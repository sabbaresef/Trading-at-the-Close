{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4936b8e3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-18T22:55:57.591679Z",
     "iopub.status.busy": "2023-12-18T22:55:57.591258Z",
     "iopub.status.idle": "2023-12-18T22:56:02.496022Z",
     "shell.execute_reply": "2023-12-18T22:56:02.494848Z"
    },
    "papermill": {
     "duration": 4.913608,
     "end_time": "2023-12-18T22:56:02.498881",
     "exception": false,
     "start_time": "2023-12-18T22:55:57.585273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import combinations\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# %load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "\n",
    "import numba as nb\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511ad68",
   "metadata": {
    "papermill": {
     "duration": 0.003829,
     "end_time": "2023-12-18T22:56:02.507503",
     "exception": false,
     "start_time": "2023-12-18T22:56:02.503674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314f870b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:56:02.518415Z",
     "iopub.status.busy": "2023-12-18T22:56:02.517644Z",
     "iopub.status.idle": "2023-12-18T22:56:02.642250Z",
     "shell.execute_reply": "2023-12-18T22:56:02.641054Z"
    },
    "papermill": {
     "duration": 0.13332,
     "end_time": "2023-12-18T22:56:02.644883",
     "exception": false,
     "start_time": "2023-12-18T22:56:02.511563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@nb.jit(nopython=False, parallel=True)\n",
    "def reduce_mem_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in range(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "    return imbalance_features\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, fastmath=True)\n",
    "def calculate_triplet_imbalance(price, df):\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_weighted_wap(df):\n",
    "    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n",
    "    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
    "    df['wap_momentum'] = df.groupby('stock_id')['weighted_wap'].pct_change(periods=6)\n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_rolling_mean_and_std_expressions(df):\n",
    "    # Convert from pandas to Polars\n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    # Define the windows and columns for which you want to calculate the rolling statistics\n",
    "    windows = [3, 5, 10]\n",
    "    columns = ['ask_price', 'bid_price', 'ask_size', 'bid_size']\n",
    "\n",
    "    # prepare the operations for each column and window\n",
    "    group = [\"stock_id\"]\n",
    "    expressions = []\n",
    "\n",
    "    # Loop over each window and column to create the rolling mean and std expressions\n",
    "    for window in windows:\n",
    "        for col in columns:\n",
    "            rolling_mean_expr = (\n",
    "                pl.col(f\"{col}_diff_{window}\")\n",
    "                .rolling_mean(window)\n",
    "                .over(group)\n",
    "                .alias(f'rolling_diff_{col}_{window}')\n",
    "            )\n",
    "\n",
    "            rolling_std_expr = (\n",
    "                pl.col(f\"{col}_diff_{window}\")\n",
    "                .rolling_std(window)\n",
    "                .over(group)\n",
    "                .alias(f'rolling_std_diff_{col}_{window}')\n",
    "            )\n",
    "\n",
    "            expressions.append(rolling_mean_expr)\n",
    "            expressions.append(rolling_std_expr)\n",
    "\n",
    "    # Run the operations using Polars' lazy API\n",
    "    lazy_df = pl_df.lazy().with_columns(expressions)\n",
    "\n",
    "    # Execute the lazy expressions and overwrite the pl_df variable\n",
    "    pl_df = lazy_df.collect()\n",
    "\n",
    "    # Convert back to pandas if necessary\n",
    "    df = pl_df.to_pandas()\n",
    "    \n",
    "    return df\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_diff_features(df):\n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['imb_s1', 'ask_price', 'bid_price', 'wap', 'ask_size', 'bid_size', 'weighted_wap', 'price_spread']:\n",
    "        for window in [3, 5, 10]: # 2\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby([\"stock_id\", \"date_id\"])[col].diff(window)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_gain_loss_features(df):\n",
    "    window = 5\n",
    "    for col in ['imb_s1', 'ask_price', 'bid_price', 'wap']:\n",
    "        df[f\"{col}_gain\"] = df[f\"{col}_diff_{window}\"].where(df[f\"{col}_diff_{window}\"] > 0, 0)\n",
    "        df[f\"{col}_loss\"] = df[f\"{col}_diff_{window}\"].where(df[f\"{col}_diff_{window}\"] < 0, 0)\n",
    "        df[f\"{col}_gain_avg\"] = df[f\"{col}_gain\"].rolling(window=window).mean()\n",
    "        df[f\"{col}_loss_avg\"] = df[f\"{col}_loss\"].rolling(window=window).mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_norm_features(df):\n",
    "    grouped = df.groupby([\"stock_id\", \"date_id\"])\n",
    "    for col in ['imb_s1', 'ask_price', 'bid_price', 'wap']:\n",
    "        df[f\"{col}_cummax\"] = grouped[col].cummax() \n",
    "        df[f\"{col}_cummin\"] = grouped[col].cummin() \n",
    "        df[f\"{col}_min_max_norm\"] = df.eval(f'({col} - {col}_cummin) / ({col}_cummax - {col}_cummin)')\n",
    "        \n",
    "    columns_to_keep = [col for col in df.columns if 'cummax' not in col]\n",
    "    df = df[columns_to_keep]\n",
    "    columns_to_keep = [col for col in df.columns if 'cummin' not in col]\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_bollinger(df):\n",
    "    # Bollinger Bands \n",
    "    periods = [3, 5, 7, 9]\n",
    "    for col in ['imb_s1', 'ask_price', 'bid_price', 'wap']:\n",
    "        grouped = df.groupby([\"stock_id\", \"date_id\"])[col]\n",
    "        for p in periods: \n",
    "            grouped_std = grouped.rolling(window=p).std().reset_index(drop=True)            \n",
    "            df[f\"{col}_bollinger_upper_{p}\"] = df[f\"{col}\"] + 2 * grouped_std\n",
    "            df[f\"{col}_bollinger_lower_{p}\"] = df[f\"{col}\"] - 2 * grouped_std\n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_diff_2_features(df):\n",
    "    for window in [3, 5, 10]:\n",
    "        df[f'price_change_diff_{window}'] = df[f'bid_price_diff_{window}'] - df[f'ask_price_diff_{window}']\n",
    "        df[f'size_change_diff_{window}'] = df[f'bid_size_diff_{window}'] - df[f'ask_size_diff_{window}']\n",
    "    return df\n",
    "        \n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_all_prices_and_sizes_features(df, prices, sizes):\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def calculate_pct_change_features(df, prices):\n",
    "    for i in range(len(prices)-1):\n",
    "        p1 = prices[i]\n",
    "        for j in range(i+1, len(prices)):\n",
    "            p2 = prices[j]\n",
    "            df[f'{p1}_{p2}_pct_change'] = ((df[p1] - df[p2]) / df[p2]) * 100\n",
    "    return df\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def compute_combination_features(df, prices):\n",
    "    for c in combinations(prices, 2):\n",
    "        # df[f'{c[0]}_minus_{c[1]}'] = df[f'{c[0]}'] - df[f'{c[1]}']\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]} - {c[1]}) / ({c[0]} + {c[1]})')\n",
    "        # df[f'{c[0]}_{c[1]}_urgency'] = df[f'{c[0]}_minus_{c[1]}'] * df['imb_s1']\n",
    "    # columns_to_keep = [col for col in df.columns if 'minus' not in col]\n",
    "    # df = df[columns_to_keep]\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def feat_eng(df):   \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id', 'currently_scored']]\n",
    "    df = df[cols]\n",
    "    \n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    df = calculate_weighted_wap(df)\n",
    "        \n",
    "    # Adding some features\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60\n",
    "    df['time_to_market_close'] = 540 - df['seconds_in_bucket']\n",
    "    \n",
    "    df['imbalance_buy_flag'] = np.where(df['imbalance_buy_sell_flag']==1, 1, 0) \n",
    "    df['imbalance_sell_flag'] = np.where(df['imbalance_buy_sell_flag']==-1, 1, 0) \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + df['ask_size']\n",
    "    df['imbalance_ratio'] = df.eval('imbalance_size / matched_size')\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size - ask_size) / (bid_size + ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size - matched_size) / (matched_size + imbalance_size)')\n",
    "    \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size - matched_size)/(matched_size + imbalance_size)\")\n",
    "        \n",
    "    df['ask_x_size'] = df.eval('ask_size * ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size * bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    df['relative_spread'] = (df['ask_price'] - df['bid_price']) / df['wap']\n",
    "    df['harmonic_imbalance'] = df.eval('2 / ((1 / bid_size) + (1 / ask_size))')\n",
    "    \n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df['market_urgency'] = df['price_spread'] * df['imb_s1']\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    \n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df['mid_price_movement'] = df['mid_price'].diff(periods=5).apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    df['mid_price*volume'] = df['mid_price_movement'] * df['volume']\n",
    "    \n",
    "    df = calculate_diff_features(df)\n",
    "    df = calculate_rolling_mean_and_std_expressions(df)\n",
    "    # df = calculate_gain_loss_features(df)\n",
    "    df = calculate_norm_features(df)\n",
    "    df = calculate_bollinger(df)\n",
    "          \n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "        \n",
    "    df = compute_combination_features(df, prices)\n",
    "    df = calculate_all_prices_and_sizes_features(df, prices, sizes)\n",
    "    df = calculate_diff_2_features(df)\n",
    "    # df = calculate_pct_change_features(df, prices)\n",
    "            \n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "        \n",
    "    df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['global_median_vol'], 1, 0) \n",
    "    \n",
    "    # Reduce memory usage\n",
    "    df = reduce_mem_usage(df)\n",
    "    \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "weights = {int(k):v for k,v in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63483ce5",
   "metadata": {
    "papermill": {
     "duration": 0.004061,
     "end_time": "2023-12-18T22:56:02.653122",
     "exception": false,
     "start_time": "2023-12-18T22:56:02.649061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f9ce4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T22:56:02.663444Z",
     "iopub.status.busy": "2023-12-18T22:56:02.662423Z",
     "iopub.status.idle": "2023-12-18T23:00:12.301033Z",
     "shell.execute_reply": "2023-12-18T23:00:12.299823Z"
    },
    "papermill": {
     "duration": 249.646832,
     "end_time": "2023-12-18T23:00:12.303950",
     "exception": false,
     "start_time": "2023-12-18T22:56:02.657118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "\n",
    "# Drop nan on target column\n",
    "train.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "global_stock_id_feats = {\n",
    "        \"median_vol\": train.groupby(\"stock_id\")[\"bid_size\"].median() + train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": train.groupby(\"stock_id\")[\"bid_size\"].std() + train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": train.groupby(\"stock_id\")[\"bid_size\"].max() - train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": train.groupby(\"stock_id\")[\"bid_price\"].median() + train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": train.groupby(\"stock_id\")[\"bid_price\"].std() + train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": train.groupby(\"stock_id\")[\"bid_price\"].max() - train.groupby(\"stock_id\")[\"ask_price\"].min()\n",
    "}\n",
    "\n",
    "# Run garbage collector\n",
    "gc.collect()\n",
    "\n",
    "# Drop other relevant nan\n",
    "train.dropna(subset=['bid_price', 'ask_price', 'wap'], inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "train.reset_index(drop=True)\n",
    "\n",
    "# Apply features engineering\n",
    "train = feat_eng(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56749aea",
   "metadata": {
    "papermill": {
     "duration": 0.003934,
     "end_time": "2023-12-18T23:00:12.312511",
     "exception": false,
     "start_time": "2023-12-18T23:00:12.308577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d196e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T23:00:12.323103Z",
     "iopub.status.busy": "2023-12-18T23:00:12.322663Z",
     "iopub.status.idle": "2023-12-18T23:03:22.796842Z",
     "shell.execute_reply": "2023-12-18T23:03:22.795479Z"
    },
    "papermill": {
     "duration": 190.48327,
     "end_time": "2023-12-18T23:03:22.799893",
     "exception": false,
     "start_time": "2023-12-18T23:00:12.316623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_models = 6\n",
    "cluster_cols = ['wap', 'reference_price', 'ask_price', 'bid_price', 'imb_s1', 'weighted_wap', 'target']\n",
    "kmeans = KMeans(n_clusters=n_models)\n",
    "X = train.drop(columns=['date_id'])\n",
    "train['cluster'] = kmeans.fit_predict(train[cluster_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a3c94",
   "metadata": {
    "papermill": {
     "duration": 0.004077,
     "end_time": "2023-12-18T23:03:22.808931",
     "exception": false,
     "start_time": "2023-12-18T23:03:22.804854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92df5e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T23:03:22.819989Z",
     "iopub.status.busy": "2023-12-18T23:03:22.818733Z",
     "iopub.status.idle": "2023-12-19T00:56:18.696040Z",
     "shell.execute_reply": "2023-12-19T00:56:18.694947Z"
    },
    "papermill": {
     "duration": 6775.885094,
     "end_time": "2023-12-19T00:56:18.698227",
     "exception": false,
     "start_time": "2023-12-18T23:03:22.813133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.036536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34797\n",
      "[LightGBM] [Info] Number of data points in the train set: 3928320, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.911860\n",
      "[LightGBM] [Info] Start training from score -0.989755\n",
      "[LightGBM] [Info] Start training from score -1.096277\n",
      "[LightGBM] [Info] Start training from score -3.849720\n",
      "[LightGBM] [Info] Start training from score -4.306562\n",
      "[LightGBM] [Info] Start training from score -2.192395\n",
      "Training until validation scores don't improve for 16 rounds\n",
      "[4]\tvalid_0's multi_logloss: 1.39435\n",
      "[8]\tvalid_0's multi_logloss: 1.38865\n",
      "[12]\tvalid_0's multi_logloss: 1.38351\n",
      "[16]\tvalid_0's multi_logloss: 1.3789\n",
      "[20]\tvalid_0's multi_logloss: 1.37463\n",
      "[24]\tvalid_0's multi_logloss: 1.37073\n",
      "[28]\tvalid_0's multi_logloss: 1.36714\n",
      "[32]\tvalid_0's multi_logloss: 1.36383\n",
      "[36]\tvalid_0's multi_logloss: 1.36075\n",
      "[40]\tvalid_0's multi_logloss: 1.35794\n",
      "[44]\tvalid_0's multi_logloss: 1.35532\n",
      "[48]\tvalid_0's multi_logloss: 1.35287\n",
      "[52]\tvalid_0's multi_logloss: 1.35057\n",
      "[56]\tvalid_0's multi_logloss: 1.34846\n",
      "[60]\tvalid_0's multi_logloss: 1.34647\n",
      "[64]\tvalid_0's multi_logloss: 1.34459\n",
      "[68]\tvalid_0's multi_logloss: 1.34285\n",
      "[72]\tvalid_0's multi_logloss: 1.34123\n",
      "[76]\tvalid_0's multi_logloss: 1.33969\n",
      "[80]\tvalid_0's multi_logloss: 1.33824\n",
      "[84]\tvalid_0's multi_logloss: 1.33689\n",
      "[88]\tvalid_0's multi_logloss: 1.3356\n",
      "[92]\tvalid_0's multi_logloss: 1.33438\n",
      "[96]\tvalid_0's multi_logloss: 1.33324\n",
      "[100]\tvalid_0's multi_logloss: 1.33217\n",
      "[104]\tvalid_0's multi_logloss: 1.33114\n",
      "[108]\tvalid_0's multi_logloss: 1.33017\n",
      "[112]\tvalid_0's multi_logloss: 1.32924\n",
      "[116]\tvalid_0's multi_logloss: 1.32836\n",
      "[120]\tvalid_0's multi_logloss: 1.32752\n",
      "[124]\tvalid_0's multi_logloss: 1.32672\n",
      "[128]\tvalid_0's multi_logloss: 1.32597\n",
      "[132]\tvalid_0's multi_logloss: 1.32525\n",
      "[136]\tvalid_0's multi_logloss: 1.32457\n",
      "[140]\tvalid_0's multi_logloss: 1.32392\n",
      "[144]\tvalid_0's multi_logloss: 1.3233\n",
      "[148]\tvalid_0's multi_logloss: 1.32271\n",
      "[152]\tvalid_0's multi_logloss: 1.32213\n",
      "[156]\tvalid_0's multi_logloss: 1.32159\n",
      "[160]\tvalid_0's multi_logloss: 1.32106\n",
      "[164]\tvalid_0's multi_logloss: 1.32056\n",
      "[168]\tvalid_0's multi_logloss: 1.32007\n",
      "[172]\tvalid_0's multi_logloss: 1.31961\n",
      "[176]\tvalid_0's multi_logloss: 1.31917\n",
      "[180]\tvalid_0's multi_logloss: 1.31874\n",
      "[184]\tvalid_0's multi_logloss: 1.31832\n",
      "[188]\tvalid_0's multi_logloss: 1.31792\n",
      "[192]\tvalid_0's multi_logloss: 1.31753\n",
      "[196]\tvalid_0's multi_logloss: 1.31716\n",
      "[200]\tvalid_0's multi_logloss: 1.31679\n",
      "[204]\tvalid_0's multi_logloss: 1.31645\n",
      "[208]\tvalid_0's multi_logloss: 1.31612\n",
      "[212]\tvalid_0's multi_logloss: 1.31579\n",
      "[216]\tvalid_0's multi_logloss: 1.31548\n",
      "[220]\tvalid_0's multi_logloss: 1.31517\n",
      "[224]\tvalid_0's multi_logloss: 1.31488\n",
      "[228]\tvalid_0's multi_logloss: 1.31459\n",
      "[232]\tvalid_0's multi_logloss: 1.3143\n",
      "[236]\tvalid_0's multi_logloss: 1.31402\n",
      "[240]\tvalid_0's multi_logloss: 1.31374\n",
      "[244]\tvalid_0's multi_logloss: 1.31347\n",
      "[248]\tvalid_0's multi_logloss: 1.31321\n",
      "[252]\tvalid_0's multi_logloss: 1.31295\n",
      "[256]\tvalid_0's multi_logloss: 1.3127\n",
      "[260]\tvalid_0's multi_logloss: 1.31245\n",
      "[264]\tvalid_0's multi_logloss: 1.31221\n",
      "[268]\tvalid_0's multi_logloss: 1.31197\n",
      "[272]\tvalid_0's multi_logloss: 1.31174\n",
      "[276]\tvalid_0's multi_logloss: 1.31151\n",
      "[280]\tvalid_0's multi_logloss: 1.31129\n",
      "[284]\tvalid_0's multi_logloss: 1.31107\n",
      "[288]\tvalid_0's multi_logloss: 1.31085\n",
      "[292]\tvalid_0's multi_logloss: 1.31065\n",
      "[296]\tvalid_0's multi_logloss: 1.31044\n",
      "[300]\tvalid_0's multi_logloss: 1.31025\n",
      "[304]\tvalid_0's multi_logloss: 1.31005\n",
      "[308]\tvalid_0's multi_logloss: 1.30986\n",
      "[312]\tvalid_0's multi_logloss: 1.30968\n",
      "[316]\tvalid_0's multi_logloss: 1.30951\n",
      "[320]\tvalid_0's multi_logloss: 1.30933\n",
      "[324]\tvalid_0's multi_logloss: 1.30917\n",
      "[328]\tvalid_0's multi_logloss: 1.309\n",
      "[332]\tvalid_0's multi_logloss: 1.30884\n",
      "[336]\tvalid_0's multi_logloss: 1.30868\n",
      "[340]\tvalid_0's multi_logloss: 1.30853\n",
      "[344]\tvalid_0's multi_logloss: 1.30837\n",
      "[348]\tvalid_0's multi_logloss: 1.30822\n",
      "[352]\tvalid_0's multi_logloss: 1.30808\n",
      "[356]\tvalid_0's multi_logloss: 1.30793\n",
      "[360]\tvalid_0's multi_logloss: 1.30779\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[360]\tvalid_0's multi_logloss: 1.30779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "stopping_rounds = 16\n",
    "log_evaluation_periods = 4\n",
    "\n",
    "y = train['cluster']\n",
    "X = train.drop(columns=['target', 'date_id', 'cluster'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=42)\n",
    "\n",
    "lgb_params = {\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 136,\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': n_models,\n",
    "    'n_estimators': 360,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'learning_rate': 0.01,\n",
    "    'reg_alpha': 0.00001,\n",
    "    'reg_lambda': 0.00001,\n",
    "    'importance_type' : 'gain',\n",
    "    'subsample': 0.70,\n",
    "    'verbosity': 1,\n",
    "    'device': device,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "# Run garbage collector\n",
    "gc.collect()\n",
    "\n",
    "# Define a LightGBM model for the current fold\n",
    "lgb_model_classifier = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# Train the LightGBM model for the current fold\n",
    "lgb_model_classifier.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    callbacks=[\n",
    "        lgb.callback.early_stopping(stopping_rounds=stopping_rounds),\n",
    "        lgb.callback.log_evaluation(period=log_evaluation_periods),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Free up memory by deleting fold specific variables\n",
    "del X, y, X_train, y_train, X_valid, y_valid\n",
    "    \n",
    "# Run garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28344b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T00:56:18.720560Z",
     "iopub.status.busy": "2023-12-19T00:56:18.720144Z",
     "iopub.status.idle": "2023-12-19T00:56:18.726891Z",
     "shell.execute_reply": "2023-12-19T00:56:18.725788Z"
    },
    "papermill": {
     "duration": 0.020826,
     "end_time": "2023-12-19T00:56:18.729182",
     "exception": false,
     "start_time": "2023-12-19T00:56:18.708356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.metrics import accuracy_score\\ny_pred = lgb_model_classifier.predict(X_valid)\\ny_pred_classes = np.argmax(y_pred)\\naccuracy = accuracy_score(y_true=y_valid, y_pred=y_pred)\\nprint(f'Accuracy: {accuracy}')\\n\\n# Free up memory by deleting fold specific variables\\ndel X, y, X_train, y_train, X_valid, y_valid\\n    \\n# Run garbage collector\\ngc.collect()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = lgb_model_classifier.predict(X_valid)\n",
    "y_pred_classes = np.argmax(y_pred)\n",
    "accuracy = accuracy_score(y_true=y_valid, y_pred=y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Free up memory by deleting fold specific variables\n",
    "del X, y, X_train, y_train, X_valid, y_valid\n",
    "    \n",
    "# Run garbage collector\n",
    "gc.collect()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe51d5",
   "metadata": {
    "papermill": {
     "duration": 0.010302,
     "end_time": "2023-12-19T00:56:18.750333",
     "exception": false,
     "start_time": "2023-12-19T00:56:18.740031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ec2e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T00:56:18.774009Z",
     "iopub.status.busy": "2023-12-19T00:56:18.773011Z",
     "iopub.status.idle": "2023-12-19T01:51:48.059197Z",
     "shell.execute_reply": "2023-12-19T01:51:48.057730Z"
    },
    "papermill": {
     "duration": 3329.300785,
     "end_time": "2023-12-19T01:51:48.061689",
     "exception": false,
     "start_time": "2023-12-19T00:56:18.760904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LGBM Regressor for cluster 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.333838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34360\n",
      "[LightGBM] [Info] Number of data points in the train set: 1556912, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -2.458984\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 1.73362\n",
      "[8]\tvalid_0's l1: 1.73263\n",
      "[12]\tvalid_0's l1: 1.73168\n",
      "[16]\tvalid_0's l1: 1.73078\n",
      "[20]\tvalid_0's l1: 1.72994\n",
      "[24]\tvalid_0's l1: 1.72915\n",
      "[28]\tvalid_0's l1: 1.72839\n",
      "[32]\tvalid_0's l1: 1.72768\n",
      "[36]\tvalid_0's l1: 1.72697\n",
      "[40]\tvalid_0's l1: 1.72631\n",
      "[44]\tvalid_0's l1: 1.7257\n",
      "[48]\tvalid_0's l1: 1.72511\n",
      "[52]\tvalid_0's l1: 1.72456\n",
      "[56]\tvalid_0's l1: 1.72402\n",
      "[60]\tvalid_0's l1: 1.72352\n",
      "[64]\tvalid_0's l1: 1.72304\n",
      "[68]\tvalid_0's l1: 1.72259\n",
      "[72]\tvalid_0's l1: 1.72216\n",
      "[76]\tvalid_0's l1: 1.72174\n",
      "[80]\tvalid_0's l1: 1.72136\n",
      "[84]\tvalid_0's l1: 1.72098\n",
      "[88]\tvalid_0's l1: 1.72062\n",
      "[92]\tvalid_0's l1: 1.72027\n",
      "[96]\tvalid_0's l1: 1.71994\n",
      "[100]\tvalid_0's l1: 1.71962\n",
      "[104]\tvalid_0's l1: 1.71932\n",
      "[108]\tvalid_0's l1: 1.71903\n",
      "[112]\tvalid_0's l1: 1.71877\n",
      "[116]\tvalid_0's l1: 1.71852\n",
      "[120]\tvalid_0's l1: 1.71828\n",
      "[124]\tvalid_0's l1: 1.71807\n",
      "[128]\tvalid_0's l1: 1.71784\n",
      "[132]\tvalid_0's l1: 1.71762\n",
      "[136]\tvalid_0's l1: 1.71742\n",
      "[140]\tvalid_0's l1: 1.71724\n",
      "[144]\tvalid_0's l1: 1.71706\n",
      "[148]\tvalid_0's l1: 1.71689\n",
      "[152]\tvalid_0's l1: 1.71672\n",
      "[156]\tvalid_0's l1: 1.71656\n",
      "[160]\tvalid_0's l1: 1.71641\n",
      "[164]\tvalid_0's l1: 1.71626\n",
      "[168]\tvalid_0's l1: 1.71612\n",
      "[172]\tvalid_0's l1: 1.71598\n",
      "[176]\tvalid_0's l1: 1.71585\n",
      "[180]\tvalid_0's l1: 1.71572\n",
      "[184]\tvalid_0's l1: 1.71559\n",
      "[188]\tvalid_0's l1: 1.71547\n",
      "[192]\tvalid_0's l1: 1.71536\n",
      "[196]\tvalid_0's l1: 1.71524\n",
      "[200]\tvalid_0's l1: 1.71514\n",
      "[204]\tvalid_0's l1: 1.71503\n",
      "[208]\tvalid_0's l1: 1.71493\n",
      "[212]\tvalid_0's l1: 1.71484\n",
      "[216]\tvalid_0's l1: 1.71474\n",
      "[220]\tvalid_0's l1: 1.71464\n",
      "[224]\tvalid_0's l1: 1.71454\n",
      "[228]\tvalid_0's l1: 1.71444\n",
      "[232]\tvalid_0's l1: 1.71434\n",
      "[236]\tvalid_0's l1: 1.71426\n",
      "[240]\tvalid_0's l1: 1.71418\n",
      "[244]\tvalid_0's l1: 1.7141\n",
      "[248]\tvalid_0's l1: 1.71402\n",
      "[252]\tvalid_0's l1: 1.71395\n",
      "[256]\tvalid_0's l1: 1.71388\n",
      "[260]\tvalid_0's l1: 1.71382\n",
      "[264]\tvalid_0's l1: 1.71375\n",
      "[268]\tvalid_0's l1: 1.71368\n",
      "[272]\tvalid_0's l1: 1.71362\n",
      "[276]\tvalid_0's l1: 1.71357\n",
      "[280]\tvalid_0's l1: 1.7135\n",
      "[284]\tvalid_0's l1: 1.71344\n",
      "[288]\tvalid_0's l1: 1.71339\n",
      "[292]\tvalid_0's l1: 1.71334\n",
      "[296]\tvalid_0's l1: 1.71327\n",
      "[300]\tvalid_0's l1: 1.71322\n",
      "[304]\tvalid_0's l1: 1.71317\n",
      "[308]\tvalid_0's l1: 1.71313\n",
      "[312]\tvalid_0's l1: 1.71309\n",
      "[316]\tvalid_0's l1: 1.71304\n",
      "[320]\tvalid_0's l1: 1.713\n",
      "[324]\tvalid_0's l1: 1.71296\n",
      "[328]\tvalid_0's l1: 1.71291\n",
      "[332]\tvalid_0's l1: 1.71286\n",
      "[336]\tvalid_0's l1: 1.71282\n",
      "[340]\tvalid_0's l1: 1.71277\n",
      "[344]\tvalid_0's l1: 1.71274\n",
      "[348]\tvalid_0's l1: 1.7127\n",
      "[352]\tvalid_0's l1: 1.71267\n",
      "[356]\tvalid_0's l1: 1.71263\n",
      "[360]\tvalid_0's l1: 1.71259\n",
      "[364]\tvalid_0's l1: 1.71256\n",
      "[368]\tvalid_0's l1: 1.71252\n",
      "[372]\tvalid_0's l1: 1.71248\n",
      "[376]\tvalid_0's l1: 1.71244\n",
      "[380]\tvalid_0's l1: 1.71241\n",
      "[384]\tvalid_0's l1: 1.71237\n",
      "[388]\tvalid_0's l1: 1.71233\n",
      "[392]\tvalid_0's l1: 1.71229\n",
      "[396]\tvalid_0's l1: 1.71226\n",
      "[400]\tvalid_0's l1: 1.71221\n",
      "[404]\tvalid_0's l1: 1.71219\n",
      "[408]\tvalid_0's l1: 1.71216\n",
      "[412]\tvalid_0's l1: 1.71214\n",
      "[416]\tvalid_0's l1: 1.71212\n",
      "[420]\tvalid_0's l1: 1.71209\n",
      "[424]\tvalid_0's l1: 1.71208\n",
      "[428]\tvalid_0's l1: 1.71205\n",
      "[432]\tvalid_0's l1: 1.71203\n",
      "[436]\tvalid_0's l1: 1.712\n",
      "[440]\tvalid_0's l1: 1.71198\n",
      "[444]\tvalid_0's l1: 1.71195\n",
      "[448]\tvalid_0's l1: 1.71194\n",
      "[452]\tvalid_0's l1: 1.71191\n",
      "[456]\tvalid_0's l1: 1.71189\n",
      "[460]\tvalid_0's l1: 1.71187\n",
      "[464]\tvalid_0's l1: 1.71186\n",
      "[468]\tvalid_0's l1: 1.71184\n",
      "[472]\tvalid_0's l1: 1.71181\n",
      "[476]\tvalid_0's l1: 1.71179\n",
      "[480]\tvalid_0's l1: 1.71177\n",
      "[484]\tvalid_0's l1: 1.71175\n",
      "[488]\tvalid_0's l1: 1.71173\n",
      "[492]\tvalid_0's l1: 1.71171\n",
      "[496]\tvalid_0's l1: 1.7117\n",
      "[500]\tvalid_0's l1: 1.71168\n",
      "[504]\tvalid_0's l1: 1.71167\n",
      "[508]\tvalid_0's l1: 1.71166\n",
      "[512]\tvalid_0's l1: 1.71164\n",
      "[516]\tvalid_0's l1: 1.71163\n",
      "[520]\tvalid_0's l1: 1.71161\n",
      "[524]\tvalid_0's l1: 1.71159\n",
      "[528]\tvalid_0's l1: 1.71158\n",
      "[532]\tvalid_0's l1: 1.71156\n",
      "[536]\tvalid_0's l1: 1.71156\n",
      "[540]\tvalid_0's l1: 1.71154\n",
      "[544]\tvalid_0's l1: 1.71153\n",
      "[548]\tvalid_0's l1: 1.71151\n",
      "[552]\tvalid_0's l1: 1.7115\n",
      "[556]\tvalid_0's l1: 1.7115\n",
      "[560]\tvalid_0's l1: 1.71149\n",
      "[564]\tvalid_0's l1: 1.71148\n",
      "[568]\tvalid_0's l1: 1.71147\n",
      "[572]\tvalid_0's l1: 1.71147\n",
      "[576]\tvalid_0's l1: 1.71145\n",
      "[580]\tvalid_0's l1: 1.71145\n",
      "[584]\tvalid_0's l1: 1.71144\n",
      "[588]\tvalid_0's l1: 1.71143\n",
      "[592]\tvalid_0's l1: 1.71142\n",
      "[596]\tvalid_0's l1: 1.71142\n",
      "[600]\tvalid_0's l1: 1.71141\n",
      "[604]\tvalid_0's l1: 1.71141\n",
      "[608]\tvalid_0's l1: 1.71141\n",
      "[612]\tvalid_0's l1: 1.7114\n",
      "[616]\tvalid_0's l1: 1.71139\n",
      "[620]\tvalid_0's l1: 1.71139\n",
      "[624]\tvalid_0's l1: 1.71139\n",
      "[628]\tvalid_0's l1: 1.71138\n",
      "[632]\tvalid_0's l1: 1.71138\n",
      "[636]\tvalid_0's l1: 1.71138\n",
      "[640]\tvalid_0's l1: 1.71137\n",
      "[644]\tvalid_0's l1: 1.71137\n",
      "[648]\tvalid_0's l1: 1.71137\n",
      "[652]\tvalid_0's l1: 1.71137\n",
      "[656]\tvalid_0's l1: 1.71136\n",
      "[660]\tvalid_0's l1: 1.71136\n",
      "[664]\tvalid_0's l1: 1.71136\n",
      "[668]\tvalid_0's l1: 1.71136\n",
      "[672]\tvalid_0's l1: 1.71136\n",
      "[676]\tvalid_0's l1: 1.71135\n",
      "[680]\tvalid_0's l1: 1.71135\n",
      "[684]\tvalid_0's l1: 1.71134\n",
      "[688]\tvalid_0's l1: 1.71134\n",
      "[692]\tvalid_0's l1: 1.71133\n",
      "[696]\tvalid_0's l1: 1.71132\n",
      "[700]\tvalid_0's l1: 1.71132\n",
      "[704]\tvalid_0's l1: 1.71132\n",
      "[708]\tvalid_0's l1: 1.71131\n",
      "[712]\tvalid_0's l1: 1.71131\n",
      "[716]\tvalid_0's l1: 1.71131\n",
      "[720]\tvalid_0's l1: 1.71131\n",
      "[724]\tvalid_0's l1: 1.71131\n",
      "[728]\tvalid_0's l1: 1.71131\n",
      "[732]\tvalid_0's l1: 1.7113\n",
      "[736]\tvalid_0's l1: 1.7113\n",
      "[740]\tvalid_0's l1: 1.7113\n",
      "[744]\tvalid_0's l1: 1.7113\n",
      "[748]\tvalid_0's l1: 1.71129\n",
      "[752]\tvalid_0's l1: 1.71128\n",
      "[756]\tvalid_0's l1: 1.71128\n",
      "[760]\tvalid_0's l1: 1.71129\n",
      "[764]\tvalid_0's l1: 1.71128\n",
      "[768]\tvalid_0's l1: 1.71128\n",
      "[772]\tvalid_0's l1: 1.71127\n",
      "[776]\tvalid_0's l1: 1.71127\n",
      "[780]\tvalid_0's l1: 1.71127\n",
      "[784]\tvalid_0's l1: 1.71126\n",
      "[788]\tvalid_0's l1: 1.71125\n",
      "[792]\tvalid_0's l1: 1.71125\n",
      "[796]\tvalid_0's l1: 1.71125\n",
      "[800]\tvalid_0's l1: 1.71125\n",
      "[804]\tvalid_0's l1: 1.71124\n",
      "[808]\tvalid_0's l1: 1.71124\n",
      "[812]\tvalid_0's l1: 1.71124\n",
      "[816]\tvalid_0's l1: 1.71124\n",
      "[820]\tvalid_0's l1: 1.71124\n",
      "[824]\tvalid_0's l1: 1.71124\n",
      "[828]\tvalid_0's l1: 1.71123\n",
      "[832]\tvalid_0's l1: 1.71123\n",
      "[836]\tvalid_0's l1: 1.71123\n",
      "[840]\tvalid_0's l1: 1.71123\n",
      "[844]\tvalid_0's l1: 1.71123\n",
      "[848]\tvalid_0's l1: 1.71124\n",
      "[852]\tvalid_0's l1: 1.71124\n",
      "[856]\tvalid_0's l1: 1.71124\n",
      "[860]\tvalid_0's l1: 1.71123\n",
      "[864]\tvalid_0's l1: 1.71124\n",
      "[868]\tvalid_0's l1: 1.71123\n",
      "[872]\tvalid_0's l1: 1.71123\n",
      "[876]\tvalid_0's l1: 1.71123\n",
      "[880]\tvalid_0's l1: 1.71123\n",
      "[884]\tvalid_0's l1: 1.71123\n",
      "[888]\tvalid_0's l1: 1.71123\n",
      "[892]\tvalid_0's l1: 1.71123\n",
      "[896]\tvalid_0's l1: 1.71123\n",
      "[900]\tvalid_0's l1: 1.71123\n",
      "[904]\tvalid_0's l1: 1.71123\n",
      "[908]\tvalid_0's l1: 1.71123\n",
      "[912]\tvalid_0's l1: 1.71123\n",
      "[916]\tvalid_0's l1: 1.71123\n",
      "[920]\tvalid_0's l1: 1.71123\n",
      "[924]\tvalid_0's l1: 1.71123\n",
      "[928]\tvalid_0's l1: 1.71123\n",
      "[932]\tvalid_0's l1: 1.71123\n",
      "[936]\tvalid_0's l1: 1.71123\n",
      "Early stopping, best iteration is:\n",
      "[837]\tvalid_0's l1: 1.71122\n",
      "\n",
      "\n",
      "\n",
      "Train LGBM Regressor for cluster 0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.861408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34791\n",
      "[LightGBM] [Info] Number of data points in the train set: 619394, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -10.140625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 2.63817\n",
      "[8]\tvalid_0's l1: 2.63297\n",
      "[12]\tvalid_0's l1: 2.62796\n",
      "[16]\tvalid_0's l1: 2.62317\n",
      "[20]\tvalid_0's l1: 2.61869\n",
      "[24]\tvalid_0's l1: 2.61441\n",
      "[28]\tvalid_0's l1: 2.61041\n",
      "[32]\tvalid_0's l1: 2.60661\n",
      "[36]\tvalid_0's l1: 2.60302\n",
      "[40]\tvalid_0's l1: 2.59969\n",
      "[44]\tvalid_0's l1: 2.59648\n",
      "[48]\tvalid_0's l1: 2.59343\n",
      "[52]\tvalid_0's l1: 2.5905\n",
      "[56]\tvalid_0's l1: 2.58776\n",
      "[60]\tvalid_0's l1: 2.58517\n",
      "[64]\tvalid_0's l1: 2.58275\n",
      "[68]\tvalid_0's l1: 2.58038\n",
      "[72]\tvalid_0's l1: 2.57815\n",
      "[76]\tvalid_0's l1: 2.57606\n",
      "[80]\tvalid_0's l1: 2.57406\n",
      "[84]\tvalid_0's l1: 2.57216\n",
      "[88]\tvalid_0's l1: 2.57038\n",
      "[92]\tvalid_0's l1: 2.56868\n",
      "[96]\tvalid_0's l1: 2.56707\n",
      "[100]\tvalid_0's l1: 2.56555\n",
      "[104]\tvalid_0's l1: 2.56409\n",
      "[108]\tvalid_0's l1: 2.56273\n",
      "[112]\tvalid_0's l1: 2.56142\n",
      "[116]\tvalid_0's l1: 2.56016\n",
      "[120]\tvalid_0's l1: 2.55899\n",
      "[124]\tvalid_0's l1: 2.55787\n",
      "[128]\tvalid_0's l1: 2.55678\n",
      "[132]\tvalid_0's l1: 2.55571\n",
      "[136]\tvalid_0's l1: 2.5547\n",
      "[140]\tvalid_0's l1: 2.55374\n",
      "[144]\tvalid_0's l1: 2.55283\n",
      "[148]\tvalid_0's l1: 2.55194\n",
      "[152]\tvalid_0's l1: 2.55114\n",
      "[156]\tvalid_0's l1: 2.55032\n",
      "[160]\tvalid_0's l1: 2.54959\n",
      "[164]\tvalid_0's l1: 2.54884\n",
      "[168]\tvalid_0's l1: 2.54812\n",
      "[172]\tvalid_0's l1: 2.54749\n",
      "[176]\tvalid_0's l1: 2.54686\n",
      "[180]\tvalid_0's l1: 2.54624\n",
      "[184]\tvalid_0's l1: 2.54568\n",
      "[188]\tvalid_0's l1: 2.54514\n",
      "[192]\tvalid_0's l1: 2.54462\n",
      "[196]\tvalid_0's l1: 2.54412\n",
      "[200]\tvalid_0's l1: 2.54365\n",
      "[204]\tvalid_0's l1: 2.54323\n",
      "[208]\tvalid_0's l1: 2.54275\n",
      "[212]\tvalid_0's l1: 2.54234\n",
      "[216]\tvalid_0's l1: 2.54192\n",
      "[220]\tvalid_0's l1: 2.54151\n",
      "[224]\tvalid_0's l1: 2.54109\n",
      "[228]\tvalid_0's l1: 2.54071\n",
      "[232]\tvalid_0's l1: 2.54035\n",
      "[236]\tvalid_0's l1: 2.53999\n",
      "[240]\tvalid_0's l1: 2.53963\n",
      "[244]\tvalid_0's l1: 2.53933\n",
      "[248]\tvalid_0's l1: 2.53903\n",
      "[252]\tvalid_0's l1: 2.53877\n",
      "[256]\tvalid_0's l1: 2.53847\n",
      "[260]\tvalid_0's l1: 2.53818\n",
      "[264]\tvalid_0's l1: 2.53788\n",
      "[268]\tvalid_0's l1: 2.53762\n",
      "[272]\tvalid_0's l1: 2.53735\n",
      "[276]\tvalid_0's l1: 2.53711\n",
      "[280]\tvalid_0's l1: 2.53688\n",
      "[284]\tvalid_0's l1: 2.53661\n",
      "[288]\tvalid_0's l1: 2.53637\n",
      "[292]\tvalid_0's l1: 2.53615\n",
      "[296]\tvalid_0's l1: 2.53596\n",
      "[300]\tvalid_0's l1: 2.53573\n",
      "[304]\tvalid_0's l1: 2.53554\n",
      "[308]\tvalid_0's l1: 2.53534\n",
      "[312]\tvalid_0's l1: 2.53512\n",
      "[316]\tvalid_0's l1: 2.53492\n",
      "[320]\tvalid_0's l1: 2.53474\n",
      "[324]\tvalid_0's l1: 2.53455\n",
      "[328]\tvalid_0's l1: 2.53438\n",
      "[332]\tvalid_0's l1: 2.53418\n",
      "[336]\tvalid_0's l1: 2.534\n",
      "[340]\tvalid_0's l1: 2.53381\n",
      "[344]\tvalid_0's l1: 2.53365\n",
      "[348]\tvalid_0's l1: 2.53349\n",
      "[352]\tvalid_0's l1: 2.53334\n",
      "[356]\tvalid_0's l1: 2.53323\n",
      "[360]\tvalid_0's l1: 2.5331\n",
      "[364]\tvalid_0's l1: 2.53299\n",
      "[368]\tvalid_0's l1: 2.53284\n",
      "[372]\tvalid_0's l1: 2.5327\n",
      "[376]\tvalid_0's l1: 2.53258\n",
      "[380]\tvalid_0's l1: 2.53244\n",
      "[384]\tvalid_0's l1: 2.5323\n",
      "[388]\tvalid_0's l1: 2.53219\n",
      "[392]\tvalid_0's l1: 2.53206\n",
      "[396]\tvalid_0's l1: 2.53195\n",
      "[400]\tvalid_0's l1: 2.53182\n",
      "[404]\tvalid_0's l1: 2.53172\n",
      "[408]\tvalid_0's l1: 2.53163\n",
      "[412]\tvalid_0's l1: 2.53151\n",
      "[416]\tvalid_0's l1: 2.53137\n",
      "[420]\tvalid_0's l1: 2.53125\n",
      "[424]\tvalid_0's l1: 2.53114\n",
      "[428]\tvalid_0's l1: 2.53106\n",
      "[432]\tvalid_0's l1: 2.53097\n",
      "[436]\tvalid_0's l1: 2.53085\n",
      "[440]\tvalid_0's l1: 2.53077\n",
      "[444]\tvalid_0's l1: 2.53067\n",
      "[448]\tvalid_0's l1: 2.5306\n",
      "[452]\tvalid_0's l1: 2.53053\n",
      "[456]\tvalid_0's l1: 2.53042\n",
      "[460]\tvalid_0's l1: 2.53033\n",
      "[464]\tvalid_0's l1: 2.53026\n",
      "[468]\tvalid_0's l1: 2.53019\n",
      "[472]\tvalid_0's l1: 2.53011\n",
      "[476]\tvalid_0's l1: 2.53006\n",
      "[480]\tvalid_0's l1: 2.53\n",
      "[484]\tvalid_0's l1: 2.52995\n",
      "[488]\tvalid_0's l1: 2.52988\n",
      "[492]\tvalid_0's l1: 2.52981\n",
      "[496]\tvalid_0's l1: 2.52973\n",
      "[500]\tvalid_0's l1: 2.52968\n",
      "[504]\tvalid_0's l1: 2.52962\n",
      "[508]\tvalid_0's l1: 2.52955\n",
      "[512]\tvalid_0's l1: 2.52948\n",
      "[516]\tvalid_0's l1: 2.52943\n",
      "[520]\tvalid_0's l1: 2.52937\n",
      "[524]\tvalid_0's l1: 2.5293\n",
      "[528]\tvalid_0's l1: 2.52927\n",
      "[532]\tvalid_0's l1: 2.52921\n",
      "[536]\tvalid_0's l1: 2.52914\n",
      "[540]\tvalid_0's l1: 2.52909\n",
      "[544]\tvalid_0's l1: 2.52905\n",
      "[548]\tvalid_0's l1: 2.52901\n",
      "[552]\tvalid_0's l1: 2.52894\n",
      "[556]\tvalid_0's l1: 2.52889\n",
      "[560]\tvalid_0's l1: 2.52884\n",
      "[564]\tvalid_0's l1: 2.52881\n",
      "[568]\tvalid_0's l1: 2.52876\n",
      "[572]\tvalid_0's l1: 2.5287\n",
      "[576]\tvalid_0's l1: 2.52865\n",
      "[580]\tvalid_0's l1: 2.5286\n",
      "[584]\tvalid_0's l1: 2.52857\n",
      "[588]\tvalid_0's l1: 2.52853\n",
      "[592]\tvalid_0's l1: 2.5285\n",
      "[596]\tvalid_0's l1: 2.52847\n",
      "[600]\tvalid_0's l1: 2.52845\n",
      "[604]\tvalid_0's l1: 2.52843\n",
      "[608]\tvalid_0's l1: 2.52839\n",
      "[612]\tvalid_0's l1: 2.52838\n",
      "[616]\tvalid_0's l1: 2.52833\n",
      "[620]\tvalid_0's l1: 2.5283\n",
      "[624]\tvalid_0's l1: 2.52828\n",
      "[628]\tvalid_0's l1: 2.52827\n",
      "[632]\tvalid_0's l1: 2.52824\n",
      "[636]\tvalid_0's l1: 2.52821\n",
      "[640]\tvalid_0's l1: 2.52818\n",
      "[644]\tvalid_0's l1: 2.52816\n",
      "[648]\tvalid_0's l1: 2.52815\n",
      "[652]\tvalid_0's l1: 2.52812\n",
      "[656]\tvalid_0's l1: 2.52809\n",
      "[660]\tvalid_0's l1: 2.52807\n",
      "[664]\tvalid_0's l1: 2.52804\n",
      "[668]\tvalid_0's l1: 2.52803\n",
      "[672]\tvalid_0's l1: 2.52803\n",
      "[676]\tvalid_0's l1: 2.52801\n",
      "[680]\tvalid_0's l1: 2.528\n",
      "[684]\tvalid_0's l1: 2.52797\n",
      "[688]\tvalid_0's l1: 2.52797\n",
      "[692]\tvalid_0's l1: 2.52795\n",
      "[696]\tvalid_0's l1: 2.52792\n",
      "[700]\tvalid_0's l1: 2.52791\n",
      "[704]\tvalid_0's l1: 2.52788\n",
      "[708]\tvalid_0's l1: 2.52786\n",
      "[712]\tvalid_0's l1: 2.52785\n",
      "[716]\tvalid_0's l1: 2.52785\n",
      "[720]\tvalid_0's l1: 2.52784\n",
      "[724]\tvalid_0's l1: 2.52782\n",
      "[728]\tvalid_0's l1: 2.5278\n",
      "[732]\tvalid_0's l1: 2.5278\n",
      "[736]\tvalid_0's l1: 2.52778\n",
      "[740]\tvalid_0's l1: 2.52778\n",
      "[744]\tvalid_0's l1: 2.52775\n",
      "[748]\tvalid_0's l1: 2.52773\n",
      "[752]\tvalid_0's l1: 2.52772\n",
      "[756]\tvalid_0's l1: 2.52771\n",
      "[760]\tvalid_0's l1: 2.52769\n",
      "[764]\tvalid_0's l1: 2.52769\n",
      "[768]\tvalid_0's l1: 2.52769\n",
      "[772]\tvalid_0's l1: 2.52767\n",
      "[776]\tvalid_0's l1: 2.52766\n",
      "[780]\tvalid_0's l1: 2.52766\n",
      "[784]\tvalid_0's l1: 2.52766\n",
      "[788]\tvalid_0's l1: 2.52766\n",
      "[792]\tvalid_0's l1: 2.52765\n",
      "[796]\tvalid_0's l1: 2.52765\n",
      "[800]\tvalid_0's l1: 2.52762\n",
      "[804]\tvalid_0's l1: 2.52761\n",
      "[808]\tvalid_0's l1: 2.5276\n",
      "[812]\tvalid_0's l1: 2.52758\n",
      "[816]\tvalid_0's l1: 2.52759\n",
      "[820]\tvalid_0's l1: 2.52758\n",
      "[824]\tvalid_0's l1: 2.52757\n",
      "[828]\tvalid_0's l1: 2.52756\n",
      "[832]\tvalid_0's l1: 2.52755\n",
      "[836]\tvalid_0's l1: 2.52754\n",
      "[840]\tvalid_0's l1: 2.52755\n",
      "[844]\tvalid_0's l1: 2.52756\n",
      "[848]\tvalid_0's l1: 2.52756\n",
      "[852]\tvalid_0's l1: 2.52756\n",
      "[856]\tvalid_0's l1: 2.52755\n",
      "[860]\tvalid_0's l1: 2.52754\n",
      "[864]\tvalid_0's l1: 2.52752\n",
      "[868]\tvalid_0's l1: 2.52753\n",
      "[872]\tvalid_0's l1: 2.52753\n",
      "[876]\tvalid_0's l1: 2.52752\n",
      "[880]\tvalid_0's l1: 2.52751\n",
      "[884]\tvalid_0's l1: 2.5275\n",
      "[888]\tvalid_0's l1: 2.5275\n",
      "[892]\tvalid_0's l1: 2.52749\n",
      "[896]\tvalid_0's l1: 2.52749\n",
      "[900]\tvalid_0's l1: 2.52748\n",
      "[904]\tvalid_0's l1: 2.52749\n",
      "[908]\tvalid_0's l1: 2.52748\n",
      "[912]\tvalid_0's l1: 2.52748\n",
      "[916]\tvalid_0's l1: 2.5275\n",
      "[920]\tvalid_0's l1: 2.52749\n",
      "[924]\tvalid_0's l1: 2.52749\n",
      "[928]\tvalid_0's l1: 2.52749\n",
      "[932]\tvalid_0's l1: 2.52748\n",
      "[936]\tvalid_0's l1: 2.52747\n",
      "[940]\tvalid_0's l1: 2.52747\n",
      "[944]\tvalid_0's l1: 2.52747\n",
      "[948]\tvalid_0's l1: 2.52746\n",
      "[952]\tvalid_0's l1: 2.52746\n",
      "[956]\tvalid_0's l1: 2.52746\n",
      "[960]\tvalid_0's l1: 2.52747\n",
      "[964]\tvalid_0's l1: 2.52746\n",
      "[968]\tvalid_0's l1: 2.52746\n",
      "[972]\tvalid_0's l1: 2.52745\n",
      "[976]\tvalid_0's l1: 2.52746\n",
      "[980]\tvalid_0's l1: 2.52746\n",
      "[984]\tvalid_0's l1: 2.52746\n",
      "[988]\tvalid_0's l1: 2.52747\n",
      "[992]\tvalid_0's l1: 2.52746\n",
      "[996]\tvalid_0's l1: 2.52748\n",
      "[1000]\tvalid_0's l1: 2.52747\n",
      "[1004]\tvalid_0's l1: 2.52748\n",
      "[1008]\tvalid_0's l1: 2.52747\n",
      "[1012]\tvalid_0's l1: 2.52746\n",
      "[1016]\tvalid_0's l1: 2.52745\n",
      "[1020]\tvalid_0's l1: 2.52746\n",
      "[1024]\tvalid_0's l1: 2.52744\n",
      "[1028]\tvalid_0's l1: 2.52744\n",
      "[1032]\tvalid_0's l1: 2.52743\n",
      "[1036]\tvalid_0's l1: 2.52741\n",
      "[1040]\tvalid_0's l1: 2.5274\n",
      "[1044]\tvalid_0's l1: 2.52741\n",
      "[1048]\tvalid_0's l1: 2.52741\n",
      "[1052]\tvalid_0's l1: 2.5274\n",
      "[1056]\tvalid_0's l1: 2.52739\n",
      "[1060]\tvalid_0's l1: 2.52738\n",
      "[1064]\tvalid_0's l1: 2.52738\n",
      "[1068]\tvalid_0's l1: 2.52738\n",
      "[1072]\tvalid_0's l1: 2.52737\n",
      "[1076]\tvalid_0's l1: 2.52737\n",
      "[1080]\tvalid_0's l1: 2.52736\n",
      "[1084]\tvalid_0's l1: 2.52734\n",
      "[1088]\tvalid_0's l1: 2.52734\n",
      "[1092]\tvalid_0's l1: 2.52734\n",
      "[1096]\tvalid_0's l1: 2.52733\n",
      "[1100]\tvalid_0's l1: 2.52733\n",
      "[1104]\tvalid_0's l1: 2.52732\n",
      "[1108]\tvalid_0's l1: 2.52731\n",
      "[1112]\tvalid_0's l1: 2.52729\n",
      "[1116]\tvalid_0's l1: 2.52729\n",
      "[1120]\tvalid_0's l1: 2.52728\n",
      "[1124]\tvalid_0's l1: 2.52728\n",
      "[1128]\tvalid_0's l1: 2.52726\n",
      "[1132]\tvalid_0's l1: 2.52726\n",
      "[1136]\tvalid_0's l1: 2.52724\n",
      "[1140]\tvalid_0's l1: 2.52725\n",
      "[1144]\tvalid_0's l1: 2.52724\n",
      "[1148]\tvalid_0's l1: 2.52725\n",
      "[1152]\tvalid_0's l1: 2.52725\n",
      "[1156]\tvalid_0's l1: 2.52724\n",
      "[1160]\tvalid_0's l1: 2.52725\n",
      "[1164]\tvalid_0's l1: 2.52725\n",
      "[1168]\tvalid_0's l1: 2.52726\n",
      "[1172]\tvalid_0's l1: 2.52726\n",
      "[1176]\tvalid_0's l1: 2.52726\n",
      "[1180]\tvalid_0's l1: 2.52725\n",
      "[1184]\tvalid_0's l1: 2.52724\n",
      "[1188]\tvalid_0's l1: 2.52723\n",
      "[1192]\tvalid_0's l1: 2.52722\n",
      "[1196]\tvalid_0's l1: 2.52721\n",
      "[1200]\tvalid_0's l1: 2.5272\n",
      "[1204]\tvalid_0's l1: 2.5272\n",
      "[1208]\tvalid_0's l1: 2.52721\n",
      "[1212]\tvalid_0's l1: 2.52721\n",
      "[1216]\tvalid_0's l1: 2.52718\n",
      "[1220]\tvalid_0's l1: 2.52717\n",
      "[1224]\tvalid_0's l1: 2.52719\n",
      "[1228]\tvalid_0's l1: 2.52718\n",
      "[1232]\tvalid_0's l1: 2.52718\n",
      "[1236]\tvalid_0's l1: 2.52718\n",
      "[1240]\tvalid_0's l1: 2.52719\n",
      "[1244]\tvalid_0's l1: 2.52718\n",
      "[1248]\tvalid_0's l1: 2.52718\n",
      "[1252]\tvalid_0's l1: 2.52718\n",
      "[1256]\tvalid_0's l1: 2.52719\n",
      "[1260]\tvalid_0's l1: 2.52719\n",
      "[1264]\tvalid_0's l1: 2.52721\n",
      "[1268]\tvalid_0's l1: 2.52721\n",
      "[1272]\tvalid_0's l1: 2.52721\n",
      "[1276]\tvalid_0's l1: 2.5272\n",
      "[1280]\tvalid_0's l1: 2.5272\n",
      "[1284]\tvalid_0's l1: 2.52721\n",
      "[1288]\tvalid_0's l1: 2.5272\n",
      "[1292]\tvalid_0's l1: 2.52718\n",
      "[1296]\tvalid_0's l1: 2.5272\n",
      "[1300]\tvalid_0's l1: 2.5272\n",
      "[1304]\tvalid_0's l1: 2.52719\n",
      "[1308]\tvalid_0's l1: 2.5272\n",
      "[1312]\tvalid_0's l1: 2.5272\n",
      "[1316]\tvalid_0's l1: 2.5272\n",
      "Early stopping, best iteration is:\n",
      "[1219]\tvalid_0's l1: 2.52717\n",
      "\n",
      "\n",
      "\n",
      "Train LGBM Regressor for cluster 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.311238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34359\n",
      "[LightGBM] [Info] Number of data points in the train set: 1400520, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 3.519531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 1.79496\n",
      "[8]\tvalid_0's l1: 1.79347\n",
      "[12]\tvalid_0's l1: 1.79205\n",
      "[16]\tvalid_0's l1: 1.79072\n",
      "[20]\tvalid_0's l1: 1.78945\n",
      "[24]\tvalid_0's l1: 1.78824\n",
      "[28]\tvalid_0's l1: 1.78711\n",
      "[32]\tvalid_0's l1: 1.78603\n",
      "[36]\tvalid_0's l1: 1.78501\n",
      "[40]\tvalid_0's l1: 1.78405\n",
      "[44]\tvalid_0's l1: 1.78312\n",
      "[48]\tvalid_0's l1: 1.78224\n",
      "[52]\tvalid_0's l1: 1.78139\n",
      "[56]\tvalid_0's l1: 1.78059\n",
      "[60]\tvalid_0's l1: 1.77984\n",
      "[64]\tvalid_0's l1: 1.77914\n",
      "[68]\tvalid_0's l1: 1.77848\n",
      "[72]\tvalid_0's l1: 1.77783\n",
      "[76]\tvalid_0's l1: 1.77722\n",
      "[80]\tvalid_0's l1: 1.77665\n",
      "[84]\tvalid_0's l1: 1.77612\n",
      "[88]\tvalid_0's l1: 1.77561\n",
      "[92]\tvalid_0's l1: 1.77514\n",
      "[96]\tvalid_0's l1: 1.77469\n",
      "[100]\tvalid_0's l1: 1.77425\n",
      "[104]\tvalid_0's l1: 1.77383\n",
      "[108]\tvalid_0's l1: 1.77343\n",
      "[112]\tvalid_0's l1: 1.77305\n",
      "[116]\tvalid_0's l1: 1.77269\n",
      "[120]\tvalid_0's l1: 1.77234\n",
      "[124]\tvalid_0's l1: 1.77199\n",
      "[128]\tvalid_0's l1: 1.77166\n",
      "[132]\tvalid_0's l1: 1.77135\n",
      "[136]\tvalid_0's l1: 1.77107\n",
      "[140]\tvalid_0's l1: 1.77078\n",
      "[144]\tvalid_0's l1: 1.77051\n",
      "[148]\tvalid_0's l1: 1.77026\n",
      "[152]\tvalid_0's l1: 1.76999\n",
      "[156]\tvalid_0's l1: 1.76977\n",
      "[160]\tvalid_0's l1: 1.76955\n",
      "[164]\tvalid_0's l1: 1.76935\n",
      "[168]\tvalid_0's l1: 1.76913\n",
      "[172]\tvalid_0's l1: 1.76893\n",
      "[176]\tvalid_0's l1: 1.76873\n",
      "[180]\tvalid_0's l1: 1.76855\n",
      "[184]\tvalid_0's l1: 1.76837\n",
      "[188]\tvalid_0's l1: 1.7682\n",
      "[192]\tvalid_0's l1: 1.76804\n",
      "[196]\tvalid_0's l1: 1.76789\n",
      "[200]\tvalid_0's l1: 1.76773\n",
      "[204]\tvalid_0's l1: 1.76758\n",
      "[208]\tvalid_0's l1: 1.76743\n",
      "[212]\tvalid_0's l1: 1.76729\n",
      "[216]\tvalid_0's l1: 1.76716\n",
      "[220]\tvalid_0's l1: 1.76702\n",
      "[224]\tvalid_0's l1: 1.7669\n",
      "[228]\tvalid_0's l1: 1.76677\n",
      "[232]\tvalid_0's l1: 1.76665\n",
      "[236]\tvalid_0's l1: 1.76656\n",
      "[240]\tvalid_0's l1: 1.76646\n",
      "[244]\tvalid_0's l1: 1.76636\n",
      "[248]\tvalid_0's l1: 1.76624\n",
      "[252]\tvalid_0's l1: 1.76614\n",
      "[256]\tvalid_0's l1: 1.76604\n",
      "[260]\tvalid_0's l1: 1.76595\n",
      "[264]\tvalid_0's l1: 1.76586\n",
      "[268]\tvalid_0's l1: 1.76577\n",
      "[272]\tvalid_0's l1: 1.76568\n",
      "[276]\tvalid_0's l1: 1.7656\n",
      "[280]\tvalid_0's l1: 1.76552\n",
      "[284]\tvalid_0's l1: 1.76545\n",
      "[288]\tvalid_0's l1: 1.76537\n",
      "[292]\tvalid_0's l1: 1.76529\n",
      "[296]\tvalid_0's l1: 1.76523\n",
      "[300]\tvalid_0's l1: 1.76514\n",
      "[304]\tvalid_0's l1: 1.76508\n",
      "[308]\tvalid_0's l1: 1.76502\n",
      "[312]\tvalid_0's l1: 1.76497\n",
      "[316]\tvalid_0's l1: 1.76492\n",
      "[320]\tvalid_0's l1: 1.76486\n",
      "[324]\tvalid_0's l1: 1.7648\n",
      "[328]\tvalid_0's l1: 1.76474\n",
      "[332]\tvalid_0's l1: 1.76467\n",
      "[336]\tvalid_0's l1: 1.76463\n",
      "[340]\tvalid_0's l1: 1.76459\n",
      "[344]\tvalid_0's l1: 1.76453\n",
      "[348]\tvalid_0's l1: 1.76451\n",
      "[352]\tvalid_0's l1: 1.76447\n",
      "[356]\tvalid_0's l1: 1.76442\n",
      "[360]\tvalid_0's l1: 1.76436\n",
      "[364]\tvalid_0's l1: 1.76431\n",
      "[368]\tvalid_0's l1: 1.76426\n",
      "[372]\tvalid_0's l1: 1.76422\n",
      "[376]\tvalid_0's l1: 1.76418\n",
      "[380]\tvalid_0's l1: 1.76414\n",
      "[384]\tvalid_0's l1: 1.76409\n",
      "[388]\tvalid_0's l1: 1.76404\n",
      "[392]\tvalid_0's l1: 1.76401\n",
      "[396]\tvalid_0's l1: 1.76398\n",
      "[400]\tvalid_0's l1: 1.76394\n",
      "[404]\tvalid_0's l1: 1.76391\n",
      "[408]\tvalid_0's l1: 1.76389\n",
      "[412]\tvalid_0's l1: 1.76386\n",
      "[416]\tvalid_0's l1: 1.76383\n",
      "[420]\tvalid_0's l1: 1.76379\n",
      "[424]\tvalid_0's l1: 1.76376\n",
      "[428]\tvalid_0's l1: 1.76373\n",
      "[432]\tvalid_0's l1: 1.76369\n",
      "[436]\tvalid_0's l1: 1.76368\n",
      "[440]\tvalid_0's l1: 1.76364\n",
      "[444]\tvalid_0's l1: 1.76362\n",
      "[448]\tvalid_0's l1: 1.7636\n",
      "[452]\tvalid_0's l1: 1.76357\n",
      "[456]\tvalid_0's l1: 1.76355\n",
      "[460]\tvalid_0's l1: 1.76354\n",
      "[464]\tvalid_0's l1: 1.76352\n",
      "[468]\tvalid_0's l1: 1.7635\n",
      "[472]\tvalid_0's l1: 1.76349\n",
      "[476]\tvalid_0's l1: 1.76346\n",
      "[480]\tvalid_0's l1: 1.76344\n",
      "[484]\tvalid_0's l1: 1.76342\n",
      "[488]\tvalid_0's l1: 1.76339\n",
      "[492]\tvalid_0's l1: 1.76338\n",
      "[496]\tvalid_0's l1: 1.76335\n",
      "[500]\tvalid_0's l1: 1.76333\n",
      "[504]\tvalid_0's l1: 1.76332\n",
      "[508]\tvalid_0's l1: 1.7633\n",
      "[512]\tvalid_0's l1: 1.76329\n",
      "[516]\tvalid_0's l1: 1.76327\n",
      "[520]\tvalid_0's l1: 1.76325\n",
      "[524]\tvalid_0's l1: 1.76323\n",
      "[528]\tvalid_0's l1: 1.7632\n",
      "[532]\tvalid_0's l1: 1.76317\n",
      "[536]\tvalid_0's l1: 1.76315\n",
      "[540]\tvalid_0's l1: 1.76314\n",
      "[544]\tvalid_0's l1: 1.76312\n",
      "[548]\tvalid_0's l1: 1.7631\n",
      "[552]\tvalid_0's l1: 1.76309\n",
      "[556]\tvalid_0's l1: 1.76307\n",
      "[560]\tvalid_0's l1: 1.76305\n",
      "[564]\tvalid_0's l1: 1.76303\n",
      "[568]\tvalid_0's l1: 1.76301\n",
      "[572]\tvalid_0's l1: 1.76301\n",
      "[576]\tvalid_0's l1: 1.76299\n",
      "[580]\tvalid_0's l1: 1.76297\n",
      "[584]\tvalid_0's l1: 1.76296\n",
      "[588]\tvalid_0's l1: 1.76296\n",
      "[592]\tvalid_0's l1: 1.76294\n",
      "[596]\tvalid_0's l1: 1.76292\n",
      "[600]\tvalid_0's l1: 1.76291\n",
      "[604]\tvalid_0's l1: 1.7629\n",
      "[608]\tvalid_0's l1: 1.76288\n",
      "[612]\tvalid_0's l1: 1.76288\n",
      "[616]\tvalid_0's l1: 1.76288\n",
      "[620]\tvalid_0's l1: 1.76287\n",
      "[624]\tvalid_0's l1: 1.76286\n",
      "[628]\tvalid_0's l1: 1.76284\n",
      "[632]\tvalid_0's l1: 1.76282\n",
      "[636]\tvalid_0's l1: 1.76282\n",
      "[640]\tvalid_0's l1: 1.76281\n",
      "[644]\tvalid_0's l1: 1.7628\n",
      "[648]\tvalid_0's l1: 1.7628\n",
      "[652]\tvalid_0's l1: 1.76278\n",
      "[656]\tvalid_0's l1: 1.76278\n",
      "[660]\tvalid_0's l1: 1.76277\n",
      "[664]\tvalid_0's l1: 1.76276\n",
      "[668]\tvalid_0's l1: 1.76275\n",
      "[672]\tvalid_0's l1: 1.76274\n",
      "[676]\tvalid_0's l1: 1.76274\n",
      "[680]\tvalid_0's l1: 1.76274\n",
      "[684]\tvalid_0's l1: 1.76272\n",
      "[688]\tvalid_0's l1: 1.76272\n",
      "[692]\tvalid_0's l1: 1.76272\n",
      "[696]\tvalid_0's l1: 1.76271\n",
      "[700]\tvalid_0's l1: 1.7627\n",
      "[704]\tvalid_0's l1: 1.7627\n",
      "[708]\tvalid_0's l1: 1.76268\n",
      "[712]\tvalid_0's l1: 1.76268\n",
      "[716]\tvalid_0's l1: 1.76267\n",
      "[720]\tvalid_0's l1: 1.76267\n",
      "[724]\tvalid_0's l1: 1.76266\n",
      "[728]\tvalid_0's l1: 1.76265\n",
      "[732]\tvalid_0's l1: 1.76265\n",
      "[736]\tvalid_0's l1: 1.76265\n",
      "[740]\tvalid_0's l1: 1.76264\n",
      "[744]\tvalid_0's l1: 1.76264\n",
      "[748]\tvalid_0's l1: 1.76264\n",
      "[752]\tvalid_0's l1: 1.76264\n",
      "[756]\tvalid_0's l1: 1.76263\n",
      "[760]\tvalid_0's l1: 1.76262\n",
      "[764]\tvalid_0's l1: 1.76262\n",
      "[768]\tvalid_0's l1: 1.76262\n",
      "[772]\tvalid_0's l1: 1.76262\n",
      "[776]\tvalid_0's l1: 1.76262\n",
      "[780]\tvalid_0's l1: 1.76261\n",
      "[784]\tvalid_0's l1: 1.76261\n",
      "[788]\tvalid_0's l1: 1.7626\n",
      "[792]\tvalid_0's l1: 1.7626\n",
      "[796]\tvalid_0's l1: 1.7626\n",
      "[800]\tvalid_0's l1: 1.76259\n",
      "[804]\tvalid_0's l1: 1.76259\n",
      "[808]\tvalid_0's l1: 1.76259\n",
      "[812]\tvalid_0's l1: 1.76258\n",
      "[816]\tvalid_0's l1: 1.76258\n",
      "[820]\tvalid_0's l1: 1.76257\n",
      "[824]\tvalid_0's l1: 1.76257\n",
      "[828]\tvalid_0's l1: 1.76256\n",
      "[832]\tvalid_0's l1: 1.76256\n",
      "[836]\tvalid_0's l1: 1.76256\n",
      "[840]\tvalid_0's l1: 1.76256\n",
      "[844]\tvalid_0's l1: 1.76256\n",
      "[848]\tvalid_0's l1: 1.76255\n",
      "[852]\tvalid_0's l1: 1.76255\n",
      "[856]\tvalid_0's l1: 1.76255\n",
      "[860]\tvalid_0's l1: 1.76255\n",
      "[864]\tvalid_0's l1: 1.76255\n",
      "[868]\tvalid_0's l1: 1.76255\n",
      "[872]\tvalid_0's l1: 1.76255\n",
      "[876]\tvalid_0's l1: 1.76255\n",
      "[880]\tvalid_0's l1: 1.76254\n",
      "[884]\tvalid_0's l1: 1.76254\n",
      "[888]\tvalid_0's l1: 1.76254\n",
      "[892]\tvalid_0's l1: 1.76253\n",
      "[896]\tvalid_0's l1: 1.76252\n",
      "[900]\tvalid_0's l1: 1.76252\n",
      "[904]\tvalid_0's l1: 1.76252\n",
      "[908]\tvalid_0's l1: 1.76252\n",
      "[912]\tvalid_0's l1: 1.76252\n",
      "[916]\tvalid_0's l1: 1.76253\n",
      "[920]\tvalid_0's l1: 1.76252\n",
      "[924]\tvalid_0's l1: 1.76252\n",
      "[928]\tvalid_0's l1: 1.76252\n",
      "[932]\tvalid_0's l1: 1.76252\n",
      "[936]\tvalid_0's l1: 1.76251\n",
      "[940]\tvalid_0's l1: 1.76251\n",
      "[944]\tvalid_0's l1: 1.76251\n",
      "[948]\tvalid_0's l1: 1.76251\n",
      "[952]\tvalid_0's l1: 1.76251\n",
      "[956]\tvalid_0's l1: 1.76251\n",
      "[960]\tvalid_0's l1: 1.76251\n",
      "[964]\tvalid_0's l1: 1.76251\n",
      "[968]\tvalid_0's l1: 1.7625\n",
      "[972]\tvalid_0's l1: 1.7625\n",
      "[976]\tvalid_0's l1: 1.7625\n",
      "[980]\tvalid_0's l1: 1.7625\n",
      "[984]\tvalid_0's l1: 1.7625\n",
      "[988]\tvalid_0's l1: 1.76249\n",
      "[992]\tvalid_0's l1: 1.76249\n",
      "[996]\tvalid_0's l1: 1.7625\n",
      "[1000]\tvalid_0's l1: 1.7625\n",
      "[1004]\tvalid_0's l1: 1.7625\n",
      "[1008]\tvalid_0's l1: 1.7625\n",
      "[1012]\tvalid_0's l1: 1.7625\n",
      "[1016]\tvalid_0's l1: 1.7625\n",
      "[1020]\tvalid_0's l1: 1.7625\n",
      "[1024]\tvalid_0's l1: 1.7625\n",
      "[1028]\tvalid_0's l1: 1.7625\n",
      "[1032]\tvalid_0's l1: 1.7625\n",
      "[1036]\tvalid_0's l1: 1.7625\n",
      "[1040]\tvalid_0's l1: 1.76249\n",
      "[1044]\tvalid_0's l1: 1.76249\n",
      "[1048]\tvalid_0's l1: 1.76249\n",
      "[1052]\tvalid_0's l1: 1.76248\n",
      "[1056]\tvalid_0's l1: 1.76248\n",
      "[1060]\tvalid_0's l1: 1.76248\n",
      "[1064]\tvalid_0's l1: 1.76248\n",
      "[1068]\tvalid_0's l1: 1.76248\n",
      "[1072]\tvalid_0's l1: 1.76248\n",
      "[1076]\tvalid_0's l1: 1.76248\n",
      "[1080]\tvalid_0's l1: 1.76248\n",
      "[1084]\tvalid_0's l1: 1.76248\n",
      "[1088]\tvalid_0's l1: 1.76248\n",
      "[1092]\tvalid_0's l1: 1.76248\n",
      "[1096]\tvalid_0's l1: 1.76248\n",
      "[1100]\tvalid_0's l1: 1.76248\n",
      "[1104]\tvalid_0's l1: 1.76248\n",
      "[1108]\tvalid_0's l1: 1.76248\n",
      "[1112]\tvalid_0's l1: 1.76248\n",
      "[1116]\tvalid_0's l1: 1.76248\n",
      "[1120]\tvalid_0's l1: 1.76249\n",
      "[1124]\tvalid_0's l1: 1.76249\n",
      "[1128]\tvalid_0's l1: 1.76249\n",
      "[1132]\tvalid_0's l1: 1.76249\n",
      "[1136]\tvalid_0's l1: 1.7625\n",
      "[1140]\tvalid_0's l1: 1.7625\n",
      "[1144]\tvalid_0's l1: 1.7625\n",
      "[1148]\tvalid_0's l1: 1.76249\n",
      "[1152]\tvalid_0's l1: 1.76249\n",
      "[1156]\tvalid_0's l1: 1.76249\n",
      "[1160]\tvalid_0's l1: 1.76249\n",
      "[1164]\tvalid_0's l1: 1.76249\n",
      "[1168]\tvalid_0's l1: 1.76249\n",
      "[1172]\tvalid_0's l1: 1.76249\n",
      "[1176]\tvalid_0's l1: 1.76249\n",
      "[1180]\tvalid_0's l1: 1.76249\n",
      "[1184]\tvalid_0's l1: 1.76249\n",
      "[1188]\tvalid_0's l1: 1.76249\n",
      "[1192]\tvalid_0's l1: 1.76249\n",
      "Early stopping, best iteration is:\n",
      "[1095]\tvalid_0's l1: 1.76247\n",
      "\n",
      "\n",
      "\n",
      "Train LGBM Regressor for cluster 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.658139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34893\n",
      "[LightGBM] [Info] Number of data points in the train set: 468046, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 11.929688\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 2.92788\n",
      "[8]\tvalid_0's l1: 2.92175\n",
      "[12]\tvalid_0's l1: 2.91585\n",
      "[16]\tvalid_0's l1: 2.91029\n",
      "[20]\tvalid_0's l1: 2.90499\n",
      "[24]\tvalid_0's l1: 2.89993\n",
      "[28]\tvalid_0's l1: 2.8952\n",
      "[32]\tvalid_0's l1: 2.89066\n",
      "[36]\tvalid_0's l1: 2.8863\n",
      "[40]\tvalid_0's l1: 2.8823\n",
      "[44]\tvalid_0's l1: 2.87852\n",
      "[48]\tvalid_0's l1: 2.87489\n",
      "[52]\tvalid_0's l1: 2.87134\n",
      "[56]\tvalid_0's l1: 2.86798\n",
      "[60]\tvalid_0's l1: 2.8648\n",
      "[64]\tvalid_0's l1: 2.86179\n",
      "[68]\tvalid_0's l1: 2.85892\n",
      "[72]\tvalid_0's l1: 2.85623\n",
      "[76]\tvalid_0's l1: 2.85373\n",
      "[80]\tvalid_0's l1: 2.85132\n",
      "[84]\tvalid_0's l1: 2.84905\n",
      "[88]\tvalid_0's l1: 2.84684\n",
      "[92]\tvalid_0's l1: 2.84483\n",
      "[96]\tvalid_0's l1: 2.84284\n",
      "[100]\tvalid_0's l1: 2.84102\n",
      "[104]\tvalid_0's l1: 2.83923\n",
      "[108]\tvalid_0's l1: 2.83751\n",
      "[112]\tvalid_0's l1: 2.83589\n",
      "[116]\tvalid_0's l1: 2.83434\n",
      "[120]\tvalid_0's l1: 2.83289\n",
      "[124]\tvalid_0's l1: 2.83147\n",
      "[128]\tvalid_0's l1: 2.83008\n",
      "[132]\tvalid_0's l1: 2.82879\n",
      "[136]\tvalid_0's l1: 2.82758\n",
      "[140]\tvalid_0's l1: 2.82639\n",
      "[144]\tvalid_0's l1: 2.82526\n",
      "[148]\tvalid_0's l1: 2.82419\n",
      "[152]\tvalid_0's l1: 2.82318\n",
      "[156]\tvalid_0's l1: 2.82216\n",
      "[160]\tvalid_0's l1: 2.8212\n",
      "[164]\tvalid_0's l1: 2.82022\n",
      "[168]\tvalid_0's l1: 2.81936\n",
      "[172]\tvalid_0's l1: 2.81859\n",
      "[176]\tvalid_0's l1: 2.81781\n",
      "[180]\tvalid_0's l1: 2.81698\n",
      "[184]\tvalid_0's l1: 2.81627\n",
      "[188]\tvalid_0's l1: 2.81556\n",
      "[192]\tvalid_0's l1: 2.81487\n",
      "[196]\tvalid_0's l1: 2.81418\n",
      "[200]\tvalid_0's l1: 2.81353\n",
      "[204]\tvalid_0's l1: 2.81294\n",
      "[208]\tvalid_0's l1: 2.81239\n",
      "[212]\tvalid_0's l1: 2.81191\n",
      "[216]\tvalid_0's l1: 2.81135\n",
      "[220]\tvalid_0's l1: 2.81084\n",
      "[224]\tvalid_0's l1: 2.81032\n",
      "[228]\tvalid_0's l1: 2.80985\n",
      "[232]\tvalid_0's l1: 2.80937\n",
      "[236]\tvalid_0's l1: 2.8089\n",
      "[240]\tvalid_0's l1: 2.80848\n",
      "[244]\tvalid_0's l1: 2.80803\n",
      "[248]\tvalid_0's l1: 2.80759\n",
      "[252]\tvalid_0's l1: 2.80719\n",
      "[256]\tvalid_0's l1: 2.80676\n",
      "[260]\tvalid_0's l1: 2.80636\n",
      "[264]\tvalid_0's l1: 2.80604\n",
      "[268]\tvalid_0's l1: 2.8057\n",
      "[272]\tvalid_0's l1: 2.8054\n",
      "[276]\tvalid_0's l1: 2.80511\n",
      "[280]\tvalid_0's l1: 2.80484\n",
      "[284]\tvalid_0's l1: 2.80462\n",
      "[288]\tvalid_0's l1: 2.80433\n",
      "[292]\tvalid_0's l1: 2.80404\n",
      "[296]\tvalid_0's l1: 2.80383\n",
      "[300]\tvalid_0's l1: 2.80359\n",
      "[304]\tvalid_0's l1: 2.80335\n",
      "[308]\tvalid_0's l1: 2.80315\n",
      "[312]\tvalid_0's l1: 2.80291\n",
      "[316]\tvalid_0's l1: 2.80268\n",
      "[320]\tvalid_0's l1: 2.80246\n",
      "[324]\tvalid_0's l1: 2.80226\n",
      "[328]\tvalid_0's l1: 2.80198\n",
      "[332]\tvalid_0's l1: 2.80177\n",
      "[336]\tvalid_0's l1: 2.80158\n",
      "[340]\tvalid_0's l1: 2.80138\n",
      "[344]\tvalid_0's l1: 2.80118\n",
      "[348]\tvalid_0's l1: 2.80103\n",
      "[352]\tvalid_0's l1: 2.80087\n",
      "[356]\tvalid_0's l1: 2.80071\n",
      "[360]\tvalid_0's l1: 2.80056\n",
      "[364]\tvalid_0's l1: 2.80043\n",
      "[368]\tvalid_0's l1: 2.80031\n",
      "[372]\tvalid_0's l1: 2.80014\n",
      "[376]\tvalid_0's l1: 2.79999\n",
      "[380]\tvalid_0's l1: 2.79986\n",
      "[384]\tvalid_0's l1: 2.79968\n",
      "[388]\tvalid_0's l1: 2.79954\n",
      "[392]\tvalid_0's l1: 2.79942\n",
      "[396]\tvalid_0's l1: 2.7993\n",
      "[400]\tvalid_0's l1: 2.79914\n",
      "[404]\tvalid_0's l1: 2.79897\n",
      "[408]\tvalid_0's l1: 2.79885\n",
      "[412]\tvalid_0's l1: 2.79872\n",
      "[416]\tvalid_0's l1: 2.7986\n",
      "[420]\tvalid_0's l1: 2.79852\n",
      "[424]\tvalid_0's l1: 2.79845\n",
      "[428]\tvalid_0's l1: 2.79832\n",
      "[432]\tvalid_0's l1: 2.7982\n",
      "[436]\tvalid_0's l1: 2.79808\n",
      "[440]\tvalid_0's l1: 2.79802\n",
      "[444]\tvalid_0's l1: 2.79789\n",
      "[448]\tvalid_0's l1: 2.79781\n",
      "[452]\tvalid_0's l1: 2.79772\n",
      "[456]\tvalid_0's l1: 2.79761\n",
      "[460]\tvalid_0's l1: 2.7975\n",
      "[464]\tvalid_0's l1: 2.79744\n",
      "[468]\tvalid_0's l1: 2.79736\n",
      "[472]\tvalid_0's l1: 2.79727\n",
      "[476]\tvalid_0's l1: 2.79718\n",
      "[480]\tvalid_0's l1: 2.79711\n",
      "[484]\tvalid_0's l1: 2.79702\n",
      "[488]\tvalid_0's l1: 2.79692\n",
      "[492]\tvalid_0's l1: 2.79684\n",
      "[496]\tvalid_0's l1: 2.79673\n",
      "[500]\tvalid_0's l1: 2.79663\n",
      "[504]\tvalid_0's l1: 2.79654\n",
      "[508]\tvalid_0's l1: 2.79646\n",
      "[512]\tvalid_0's l1: 2.79639\n",
      "[516]\tvalid_0's l1: 2.79629\n",
      "[520]\tvalid_0's l1: 2.79622\n",
      "[524]\tvalid_0's l1: 2.79614\n",
      "[528]\tvalid_0's l1: 2.79606\n",
      "[532]\tvalid_0's l1: 2.79599\n",
      "[536]\tvalid_0's l1: 2.79591\n",
      "[540]\tvalid_0's l1: 2.79585\n",
      "[544]\tvalid_0's l1: 2.79581\n",
      "[548]\tvalid_0's l1: 2.79576\n",
      "[552]\tvalid_0's l1: 2.79572\n",
      "[556]\tvalid_0's l1: 2.79566\n",
      "[560]\tvalid_0's l1: 2.79563\n",
      "[564]\tvalid_0's l1: 2.79562\n",
      "[568]\tvalid_0's l1: 2.79555\n",
      "[572]\tvalid_0's l1: 2.79549\n",
      "[576]\tvalid_0's l1: 2.79544\n",
      "[580]\tvalid_0's l1: 2.79541\n",
      "[584]\tvalid_0's l1: 2.79537\n",
      "[588]\tvalid_0's l1: 2.79533\n",
      "[592]\tvalid_0's l1: 2.79532\n",
      "[596]\tvalid_0's l1: 2.7953\n",
      "[600]\tvalid_0's l1: 2.79528\n",
      "[604]\tvalid_0's l1: 2.79522\n",
      "[608]\tvalid_0's l1: 2.79521\n",
      "[612]\tvalid_0's l1: 2.7952\n",
      "[616]\tvalid_0's l1: 2.79518\n",
      "[620]\tvalid_0's l1: 2.79514\n",
      "[624]\tvalid_0's l1: 2.7951\n",
      "[628]\tvalid_0's l1: 2.79505\n",
      "[632]\tvalid_0's l1: 2.795\n",
      "[636]\tvalid_0's l1: 2.79499\n",
      "[640]\tvalid_0's l1: 2.79497\n",
      "[644]\tvalid_0's l1: 2.79494\n",
      "[648]\tvalid_0's l1: 2.79494\n",
      "[652]\tvalid_0's l1: 2.79493\n",
      "[656]\tvalid_0's l1: 2.79491\n",
      "[660]\tvalid_0's l1: 2.79483\n",
      "[664]\tvalid_0's l1: 2.79481\n",
      "[668]\tvalid_0's l1: 2.7948\n",
      "[672]\tvalid_0's l1: 2.79478\n",
      "[676]\tvalid_0's l1: 2.79475\n",
      "[680]\tvalid_0's l1: 2.79473\n",
      "[684]\tvalid_0's l1: 2.79474\n",
      "[688]\tvalid_0's l1: 2.79474\n",
      "[692]\tvalid_0's l1: 2.79469\n",
      "[696]\tvalid_0's l1: 2.79469\n",
      "[700]\tvalid_0's l1: 2.79469\n",
      "[704]\tvalid_0's l1: 2.79468\n",
      "[708]\tvalid_0's l1: 2.79466\n",
      "[712]\tvalid_0's l1: 2.79465\n",
      "[716]\tvalid_0's l1: 2.79461\n",
      "[720]\tvalid_0's l1: 2.79458\n",
      "[724]\tvalid_0's l1: 2.79454\n",
      "[728]\tvalid_0's l1: 2.79453\n",
      "[732]\tvalid_0's l1: 2.79453\n",
      "[736]\tvalid_0's l1: 2.79452\n",
      "[740]\tvalid_0's l1: 2.7945\n",
      "[744]\tvalid_0's l1: 2.79447\n",
      "[748]\tvalid_0's l1: 2.79447\n",
      "[752]\tvalid_0's l1: 2.79443\n",
      "[756]\tvalid_0's l1: 2.79442\n",
      "[760]\tvalid_0's l1: 2.79439\n",
      "[764]\tvalid_0's l1: 2.79439\n",
      "[768]\tvalid_0's l1: 2.79437\n",
      "[772]\tvalid_0's l1: 2.79437\n",
      "[776]\tvalid_0's l1: 2.79434\n",
      "[780]\tvalid_0's l1: 2.79434\n",
      "[784]\tvalid_0's l1: 2.79433\n",
      "[788]\tvalid_0's l1: 2.79435\n",
      "[792]\tvalid_0's l1: 2.79433\n",
      "[796]\tvalid_0's l1: 2.79435\n",
      "[800]\tvalid_0's l1: 2.79433\n",
      "[804]\tvalid_0's l1: 2.79432\n",
      "[808]\tvalid_0's l1: 2.79433\n",
      "[812]\tvalid_0's l1: 2.79432\n",
      "[816]\tvalid_0's l1: 2.79433\n",
      "[820]\tvalid_0's l1: 2.79432\n",
      "[824]\tvalid_0's l1: 2.7943\n",
      "[828]\tvalid_0's l1: 2.79431\n",
      "[832]\tvalid_0's l1: 2.7943\n",
      "[836]\tvalid_0's l1: 2.7943\n",
      "[840]\tvalid_0's l1: 2.7943\n",
      "[844]\tvalid_0's l1: 2.7943\n",
      "[848]\tvalid_0's l1: 2.79429\n",
      "[852]\tvalid_0's l1: 2.79426\n",
      "[856]\tvalid_0's l1: 2.79426\n",
      "[860]\tvalid_0's l1: 2.79427\n",
      "[864]\tvalid_0's l1: 2.79426\n",
      "[868]\tvalid_0's l1: 2.79427\n",
      "[872]\tvalid_0's l1: 2.79429\n",
      "[876]\tvalid_0's l1: 2.7943\n",
      "[880]\tvalid_0's l1: 2.79429\n",
      "[884]\tvalid_0's l1: 2.79431\n",
      "[888]\tvalid_0's l1: 2.7943\n",
      "[892]\tvalid_0's l1: 2.7943\n",
      "[896]\tvalid_0's l1: 2.79431\n",
      "[900]\tvalid_0's l1: 2.79431\n",
      "[904]\tvalid_0's l1: 2.79431\n",
      "[908]\tvalid_0's l1: 2.79432\n",
      "[912]\tvalid_0's l1: 2.79432\n",
      "[916]\tvalid_0's l1: 2.7943\n",
      "[920]\tvalid_0's l1: 2.79429\n",
      "[924]\tvalid_0's l1: 2.79429\n",
      "[928]\tvalid_0's l1: 2.7943\n",
      "[932]\tvalid_0's l1: 2.7943\n",
      "[936]\tvalid_0's l1: 2.79431\n",
      "[940]\tvalid_0's l1: 2.79427\n",
      "[944]\tvalid_0's l1: 2.79426\n",
      "[948]\tvalid_0's l1: 2.79426\n",
      "[952]\tvalid_0's l1: 2.79424\n",
      "[956]\tvalid_0's l1: 2.79425\n",
      "[960]\tvalid_0's l1: 2.79424\n",
      "[964]\tvalid_0's l1: 2.79424\n",
      "[968]\tvalid_0's l1: 2.79424\n",
      "[972]\tvalid_0's l1: 2.79426\n",
      "[976]\tvalid_0's l1: 2.79426\n",
      "[980]\tvalid_0's l1: 2.79428\n",
      "[984]\tvalid_0's l1: 2.79428\n",
      "[988]\tvalid_0's l1: 2.79427\n",
      "[992]\tvalid_0's l1: 2.79427\n",
      "[996]\tvalid_0's l1: 2.79427\n",
      "[1000]\tvalid_0's l1: 2.79427\n",
      "[1004]\tvalid_0's l1: 2.79427\n",
      "[1008]\tvalid_0's l1: 2.79426\n",
      "[1012]\tvalid_0's l1: 2.79425\n",
      "[1016]\tvalid_0's l1: 2.79423\n",
      "[1020]\tvalid_0's l1: 2.7942\n",
      "[1024]\tvalid_0's l1: 2.79419\n",
      "[1028]\tvalid_0's l1: 2.79419\n",
      "[1032]\tvalid_0's l1: 2.79418\n",
      "[1036]\tvalid_0's l1: 2.79416\n",
      "[1040]\tvalid_0's l1: 2.79416\n",
      "[1044]\tvalid_0's l1: 2.79416\n",
      "[1048]\tvalid_0's l1: 2.79417\n",
      "[1052]\tvalid_0's l1: 2.79416\n",
      "[1056]\tvalid_0's l1: 2.79416\n",
      "[1060]\tvalid_0's l1: 2.79417\n",
      "[1064]\tvalid_0's l1: 2.79416\n",
      "[1068]\tvalid_0's l1: 2.79416\n",
      "[1072]\tvalid_0's l1: 2.79416\n",
      "[1076]\tvalid_0's l1: 2.79416\n",
      "[1080]\tvalid_0's l1: 2.79415\n",
      "[1084]\tvalid_0's l1: 2.79413\n",
      "[1088]\tvalid_0's l1: 2.79413\n",
      "[1092]\tvalid_0's l1: 2.79415\n",
      "[1096]\tvalid_0's l1: 2.79414\n",
      "[1100]\tvalid_0's l1: 2.79414\n",
      "[1104]\tvalid_0's l1: 2.79412\n",
      "[1108]\tvalid_0's l1: 2.79413\n",
      "[1112]\tvalid_0's l1: 2.79414\n",
      "[1116]\tvalid_0's l1: 2.79416\n",
      "[1120]\tvalid_0's l1: 2.79416\n",
      "[1124]\tvalid_0's l1: 2.79416\n",
      "[1128]\tvalid_0's l1: 2.79416\n",
      "[1132]\tvalid_0's l1: 2.79415\n",
      "[1136]\tvalid_0's l1: 2.79415\n",
      "[1140]\tvalid_0's l1: 2.79415\n",
      "[1144]\tvalid_0's l1: 2.79415\n",
      "[1148]\tvalid_0's l1: 2.79413\n",
      "[1152]\tvalid_0's l1: 2.79412\n",
      "[1156]\tvalid_0's l1: 2.79414\n",
      "[1160]\tvalid_0's l1: 2.79414\n",
      "[1164]\tvalid_0's l1: 2.79411\n",
      "[1168]\tvalid_0's l1: 2.79412\n",
      "[1172]\tvalid_0's l1: 2.79413\n",
      "[1176]\tvalid_0's l1: 2.79414\n",
      "[1180]\tvalid_0's l1: 2.79414\n",
      "[1184]\tvalid_0's l1: 2.79413\n",
      "[1188]\tvalid_0's l1: 2.79414\n",
      "[1192]\tvalid_0's l1: 2.79414\n",
      "[1196]\tvalid_0's l1: 2.79414\n",
      "[1200]\tvalid_0's l1: 2.79415\n",
      "[1204]\tvalid_0's l1: 2.79417\n",
      "[1208]\tvalid_0's l1: 2.79417\n",
      "[1212]\tvalid_0's l1: 2.79416\n",
      "[1216]\tvalid_0's l1: 2.79416\n",
      "[1220]\tvalid_0's l1: 2.79416\n",
      "[1224]\tvalid_0's l1: 2.79416\n",
      "[1228]\tvalid_0's l1: 2.79416\n",
      "[1232]\tvalid_0's l1: 2.79414\n",
      "[1236]\tvalid_0's l1: 2.79415\n",
      "[1240]\tvalid_0's l1: 2.79414\n",
      "[1244]\tvalid_0's l1: 2.79414\n",
      "[1248]\tvalid_0's l1: 2.79416\n",
      "[1252]\tvalid_0's l1: 2.79414\n",
      "[1256]\tvalid_0's l1: 2.79415\n",
      "[1260]\tvalid_0's l1: 2.79416\n",
      "[1264]\tvalid_0's l1: 2.79416\n",
      "Early stopping, best iteration is:\n",
      "[1164]\tvalid_0's l1: 2.79411\n",
      "\n",
      "\n",
      "\n",
      "Train LGBM Regressor for cluster 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35686\n",
      "[LightGBM] [Info] Number of data points in the train set: 89049, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -25.187500\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 6.84499\n",
      "[8]\tvalid_0's l1: 6.82383\n",
      "[12]\tvalid_0's l1: 6.80122\n",
      "[16]\tvalid_0's l1: 6.77965\n",
      "[20]\tvalid_0's l1: 6.75994\n",
      "[24]\tvalid_0's l1: 6.7415\n",
      "[28]\tvalid_0's l1: 6.72497\n",
      "[32]\tvalid_0's l1: 6.70835\n",
      "[36]\tvalid_0's l1: 6.69145\n",
      "[40]\tvalid_0's l1: 6.67605\n",
      "[44]\tvalid_0's l1: 6.66174\n",
      "[48]\tvalid_0's l1: 6.64834\n",
      "[52]\tvalid_0's l1: 6.63557\n",
      "[56]\tvalid_0's l1: 6.62184\n",
      "[60]\tvalid_0's l1: 6.61011\n",
      "[64]\tvalid_0's l1: 6.59997\n",
      "[68]\tvalid_0's l1: 6.58916\n",
      "[72]\tvalid_0's l1: 6.57892\n",
      "[76]\tvalid_0's l1: 6.57021\n",
      "[80]\tvalid_0's l1: 6.5598\n",
      "[84]\tvalid_0's l1: 6.5511\n",
      "[88]\tvalid_0's l1: 6.54315\n",
      "[92]\tvalid_0's l1: 6.53485\n",
      "[96]\tvalid_0's l1: 6.5271\n",
      "[100]\tvalid_0's l1: 6.51971\n",
      "[104]\tvalid_0's l1: 6.51279\n",
      "[108]\tvalid_0's l1: 6.50625\n",
      "[112]\tvalid_0's l1: 6.50002\n",
      "[116]\tvalid_0's l1: 6.49406\n",
      "[120]\tvalid_0's l1: 6.48772\n",
      "[124]\tvalid_0's l1: 6.48163\n",
      "[128]\tvalid_0's l1: 6.47636\n",
      "[132]\tvalid_0's l1: 6.47142\n",
      "[136]\tvalid_0's l1: 6.46649\n",
      "[140]\tvalid_0's l1: 6.46174\n",
      "[144]\tvalid_0's l1: 6.45702\n",
      "[148]\tvalid_0's l1: 6.4527\n",
      "[152]\tvalid_0's l1: 6.44799\n",
      "[156]\tvalid_0's l1: 6.44377\n",
      "[160]\tvalid_0's l1: 6.43991\n",
      "[164]\tvalid_0's l1: 6.4361\n",
      "[168]\tvalid_0's l1: 6.43271\n",
      "[172]\tvalid_0's l1: 6.42995\n",
      "[176]\tvalid_0's l1: 6.42699\n",
      "[180]\tvalid_0's l1: 6.42428\n",
      "[184]\tvalid_0's l1: 6.42068\n",
      "[188]\tvalid_0's l1: 6.41748\n",
      "[192]\tvalid_0's l1: 6.41439\n",
      "[196]\tvalid_0's l1: 6.41143\n",
      "[200]\tvalid_0's l1: 6.40869\n",
      "[204]\tvalid_0's l1: 6.40623\n",
      "[208]\tvalid_0's l1: 6.40374\n",
      "[212]\tvalid_0's l1: 6.40137\n",
      "[216]\tvalid_0's l1: 6.39948\n",
      "[220]\tvalid_0's l1: 6.39699\n",
      "[224]\tvalid_0's l1: 6.39457\n",
      "[228]\tvalid_0's l1: 6.39215\n",
      "[232]\tvalid_0's l1: 6.39106\n",
      "[236]\tvalid_0's l1: 6.38917\n",
      "[240]\tvalid_0's l1: 6.38685\n",
      "[244]\tvalid_0's l1: 6.38457\n",
      "[248]\tvalid_0's l1: 6.38302\n",
      "[252]\tvalid_0's l1: 6.38111\n",
      "[256]\tvalid_0's l1: 6.37929\n",
      "[260]\tvalid_0's l1: 6.37722\n",
      "[264]\tvalid_0's l1: 6.37572\n",
      "[268]\tvalid_0's l1: 6.37426\n",
      "[272]\tvalid_0's l1: 6.37282\n",
      "[276]\tvalid_0's l1: 6.37156\n",
      "[280]\tvalid_0's l1: 6.37023\n",
      "[284]\tvalid_0's l1: 6.36895\n",
      "[288]\tvalid_0's l1: 6.36786\n",
      "[292]\tvalid_0's l1: 6.36648\n",
      "[296]\tvalid_0's l1: 6.36482\n",
      "[300]\tvalid_0's l1: 6.36369\n",
      "[304]\tvalid_0's l1: 6.36275\n",
      "[308]\tvalid_0's l1: 6.36183\n",
      "[312]\tvalid_0's l1: 6.36091\n",
      "[316]\tvalid_0's l1: 6.36013\n",
      "[320]\tvalid_0's l1: 6.35942\n",
      "[324]\tvalid_0's l1: 6.35862\n",
      "[328]\tvalid_0's l1: 6.35792\n",
      "[332]\tvalid_0's l1: 6.35731\n",
      "[336]\tvalid_0's l1: 6.35633\n",
      "[340]\tvalid_0's l1: 6.35557\n",
      "[344]\tvalid_0's l1: 6.35486\n",
      "[348]\tvalid_0's l1: 6.35405\n",
      "[352]\tvalid_0's l1: 6.35372\n",
      "[356]\tvalid_0's l1: 6.35336\n",
      "[360]\tvalid_0's l1: 6.3525\n",
      "[364]\tvalid_0's l1: 6.35196\n",
      "[368]\tvalid_0's l1: 6.35153\n",
      "[372]\tvalid_0's l1: 6.35134\n",
      "[376]\tvalid_0's l1: 6.35109\n",
      "[380]\tvalid_0's l1: 6.35079\n",
      "[384]\tvalid_0's l1: 6.35057\n",
      "[388]\tvalid_0's l1: 6.35015\n",
      "[392]\tvalid_0's l1: 6.35005\n",
      "[396]\tvalid_0's l1: 6.34988\n",
      "[400]\tvalid_0's l1: 6.34946\n",
      "[404]\tvalid_0's l1: 6.34911\n",
      "[408]\tvalid_0's l1: 6.34867\n",
      "[412]\tvalid_0's l1: 6.34819\n",
      "[416]\tvalid_0's l1: 6.34789\n",
      "[420]\tvalid_0's l1: 6.34762\n",
      "[424]\tvalid_0's l1: 6.34729\n",
      "[428]\tvalid_0's l1: 6.3469\n",
      "[432]\tvalid_0's l1: 6.34679\n",
      "[436]\tvalid_0's l1: 6.34662\n",
      "[440]\tvalid_0's l1: 6.34657\n",
      "[444]\tvalid_0's l1: 6.3464\n",
      "[448]\tvalid_0's l1: 6.34627\n",
      "[452]\tvalid_0's l1: 6.3462\n",
      "[456]\tvalid_0's l1: 6.34589\n",
      "[460]\tvalid_0's l1: 6.34586\n",
      "[464]\tvalid_0's l1: 6.34565\n",
      "[468]\tvalid_0's l1: 6.34563\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[472]\tvalid_0's l1: 6.34539\n",
      "[476]\tvalid_0's l1: 6.34512\n",
      "[480]\tvalid_0's l1: 6.34502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[484]\tvalid_0's l1: 6.34496\n",
      "[488]\tvalid_0's l1: 6.34466\n",
      "[492]\tvalid_0's l1: 6.34418\n",
      "[496]\tvalid_0's l1: 6.34421\n",
      "[500]\tvalid_0's l1: 6.34422\n",
      "[504]\tvalid_0's l1: 6.34426\n",
      "[508]\tvalid_0's l1: 6.34401\n",
      "[512]\tvalid_0's l1: 6.34385\n",
      "[516]\tvalid_0's l1: 6.34377\n",
      "[520]\tvalid_0's l1: 6.3437\n",
      "[524]\tvalid_0's l1: 6.34367\n",
      "[528]\tvalid_0's l1: 6.34339\n",
      "[532]\tvalid_0's l1: 6.34318\n",
      "[536]\tvalid_0's l1: 6.34331\n",
      "[540]\tvalid_0's l1: 6.34312\n",
      "[544]\tvalid_0's l1: 6.34284\n",
      "[548]\tvalid_0's l1: 6.34267\n",
      "[552]\tvalid_0's l1: 6.34279\n",
      "[556]\tvalid_0's l1: 6.34298\n",
      "[560]\tvalid_0's l1: 6.34284\n",
      "[564]\tvalid_0's l1: 6.34291\n",
      "[568]\tvalid_0's l1: 6.34302\n",
      "[572]\tvalid_0's l1: 6.3436\n",
      "[576]\tvalid_0's l1: 6.34334\n",
      "[580]\tvalid_0's l1: 6.34343\n",
      "[584]\tvalid_0's l1: 6.34334\n",
      "[588]\tvalid_0's l1: 6.34317\n",
      "[592]\tvalid_0's l1: 6.34322\n",
      "[596]\tvalid_0's l1: 6.34314\n",
      "[600]\tvalid_0's l1: 6.34295\n",
      "[604]\tvalid_0's l1: 6.34285\n",
      "[608]\tvalid_0's l1: 6.34294\n",
      "[612]\tvalid_0's l1: 6.34284\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[616]\tvalid_0's l1: 6.34302\n",
      "[620]\tvalid_0's l1: 6.34279\n",
      "[624]\tvalid_0's l1: 6.34285\n",
      "[628]\tvalid_0's l1: 6.34279\n",
      "[632]\tvalid_0's l1: 6.34272\n",
      "[636]\tvalid_0's l1: 6.34263\n",
      "[640]\tvalid_0's l1: 6.34256\n",
      "[644]\tvalid_0's l1: 6.34239\n",
      "[648]\tvalid_0's l1: 6.34236\n",
      "[652]\tvalid_0's l1: 6.34236\n",
      "[656]\tvalid_0's l1: 6.34245\n",
      "[660]\tvalid_0's l1: 6.34241\n",
      "[664]\tvalid_0's l1: 6.34239\n",
      "[668]\tvalid_0's l1: 6.34221\n",
      "[672]\tvalid_0's l1: 6.34225\n",
      "[676]\tvalid_0's l1: 6.34234\n",
      "[680]\tvalid_0's l1: 6.3423\n",
      "[684]\tvalid_0's l1: 6.34218\n",
      "[688]\tvalid_0's l1: 6.34208\n",
      "[692]\tvalid_0's l1: 6.34201\n",
      "[696]\tvalid_0's l1: 6.34199\n",
      "[700]\tvalid_0's l1: 6.34173\n",
      "[704]\tvalid_0's l1: 6.34159\n",
      "[708]\tvalid_0's l1: 6.34135\n",
      "[712]\tvalid_0's l1: 6.34134\n",
      "[716]\tvalid_0's l1: 6.34119\n",
      "[720]\tvalid_0's l1: 6.34106\n",
      "[724]\tvalid_0's l1: 6.34097\n",
      "[728]\tvalid_0's l1: 6.34088\n",
      "[732]\tvalid_0's l1: 6.34074\n",
      "[736]\tvalid_0's l1: 6.34076\n",
      "[740]\tvalid_0's l1: 6.34072\n",
      "[744]\tvalid_0's l1: 6.3407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[748]\tvalid_0's l1: 6.34031\n",
      "[752]\tvalid_0's l1: 6.34035\n",
      "[756]\tvalid_0's l1: 6.34021\n",
      "[760]\tvalid_0's l1: 6.34023\n",
      "[764]\tvalid_0's l1: 6.34028\n",
      "[768]\tvalid_0's l1: 6.34011\n",
      "[772]\tvalid_0's l1: 6.34011\n",
      "[776]\tvalid_0's l1: 6.34024\n",
      "[780]\tvalid_0's l1: 6.34014\n",
      "[784]\tvalid_0's l1: 6.34015\n",
      "[788]\tvalid_0's l1: 6.34017\n",
      "[792]\tvalid_0's l1: 6.34009\n",
      "[796]\tvalid_0's l1: 6.34022\n",
      "[800]\tvalid_0's l1: 6.34023\n",
      "[804]\tvalid_0's l1: 6.34015\n",
      "[808]\tvalid_0's l1: 6.34005\n",
      "[812]\tvalid_0's l1: 6.34004\n",
      "[816]\tvalid_0's l1: 6.33998\n",
      "[820]\tvalid_0's l1: 6.33987\n",
      "[824]\tvalid_0's l1: 6.33987\n",
      "[828]\tvalid_0's l1: 6.33998\n",
      "[832]\tvalid_0's l1: 6.34003\n",
      "[836]\tvalid_0's l1: 6.3401\n",
      "[840]\tvalid_0's l1: 6.34005\n",
      "[844]\tvalid_0's l1: 6.33999\n",
      "[848]\tvalid_0's l1: 6.33988\n",
      "[852]\tvalid_0's l1: 6.33947\n",
      "[856]\tvalid_0's l1: 6.3394\n",
      "[860]\tvalid_0's l1: 6.33935\n",
      "[864]\tvalid_0's l1: 6.33945\n",
      "[868]\tvalid_0's l1: 6.33932\n",
      "[872]\tvalid_0's l1: 6.33919\n",
      "[876]\tvalid_0's l1: 6.33918\n",
      "[880]\tvalid_0's l1: 6.33921\n",
      "[884]\tvalid_0's l1: 6.3392\n",
      "[888]\tvalid_0's l1: 6.33922\n",
      "[892]\tvalid_0's l1: 6.33911\n",
      "[896]\tvalid_0's l1: 6.33904\n",
      "[900]\tvalid_0's l1: 6.33907\n",
      "[904]\tvalid_0's l1: 6.33905\n",
      "[908]\tvalid_0's l1: 6.33913\n",
      "[912]\tvalid_0's l1: 6.33907\n",
      "[916]\tvalid_0's l1: 6.33891\n",
      "[920]\tvalid_0's l1: 6.33896\n",
      "[924]\tvalid_0's l1: 6.33905\n",
      "[928]\tvalid_0's l1: 6.3391\n",
      "[932]\tvalid_0's l1: 6.33915\n",
      "[936]\tvalid_0's l1: 6.3392\n",
      "[940]\tvalid_0's l1: 6.33917\n",
      "[944]\tvalid_0's l1: 6.33913\n",
      "[948]\tvalid_0's l1: 6.33922\n",
      "[952]\tvalid_0's l1: 6.33929\n",
      "[956]\tvalid_0's l1: 6.33934\n",
      "[960]\tvalid_0's l1: 6.33932\n",
      "[964]\tvalid_0's l1: 6.33949\n",
      "[968]\tvalid_0's l1: 6.3394\n",
      "[972]\tvalid_0's l1: 6.33942\n",
      "[976]\tvalid_0's l1: 6.33946\n",
      "[980]\tvalid_0's l1: 6.33956\n",
      "[984]\tvalid_0's l1: 6.33951\n",
      "[988]\tvalid_0's l1: 6.33952\n",
      "[992]\tvalid_0's l1: 6.33947\n",
      "[996]\tvalid_0's l1: 6.33918\n",
      "[1000]\tvalid_0's l1: 6.33892\n",
      "[1004]\tvalid_0's l1: 6.33887\n",
      "[1008]\tvalid_0's l1: 6.33878\n",
      "[1012]\tvalid_0's l1: 6.33864\n",
      "[1016]\tvalid_0's l1: 6.33861\n",
      "[1020]\tvalid_0's l1: 6.33837\n",
      "[1024]\tvalid_0's l1: 6.3384\n",
      "[1028]\tvalid_0's l1: 6.33833\n",
      "[1032]\tvalid_0's l1: 6.33826\n",
      "[1036]\tvalid_0's l1: 6.33829\n",
      "[1040]\tvalid_0's l1: 6.33838\n",
      "[1044]\tvalid_0's l1: 6.33839\n",
      "[1048]\tvalid_0's l1: 6.33834\n",
      "[1052]\tvalid_0's l1: 6.33818\n",
      "[1056]\tvalid_0's l1: 6.33825\n",
      "[1060]\tvalid_0's l1: 6.33825\n",
      "[1064]\tvalid_0's l1: 6.33814\n",
      "[1068]\tvalid_0's l1: 6.33814\n",
      "[1072]\tvalid_0's l1: 6.33817\n",
      "[1076]\tvalid_0's l1: 6.33828\n",
      "[1080]\tvalid_0's l1: 6.33827\n",
      "[1084]\tvalid_0's l1: 6.33826\n",
      "[1088]\tvalid_0's l1: 6.33824\n",
      "[1092]\tvalid_0's l1: 6.33829\n",
      "[1096]\tvalid_0's l1: 6.33817\n",
      "[1100]\tvalid_0's l1: 6.33817\n",
      "[1104]\tvalid_0's l1: 6.33815\n",
      "[1108]\tvalid_0's l1: 6.33818\n",
      "[1112]\tvalid_0's l1: 6.33826\n",
      "[1116]\tvalid_0's l1: 6.3382\n",
      "[1120]\tvalid_0's l1: 6.33813\n",
      "[1124]\tvalid_0's l1: 6.33811\n",
      "[1128]\tvalid_0's l1: 6.3381\n",
      "[1132]\tvalid_0's l1: 6.33812\n",
      "[1136]\tvalid_0's l1: 6.33814\n",
      "[1140]\tvalid_0's l1: 6.33811\n",
      "[1144]\tvalid_0's l1: 6.33814\n",
      "[1148]\tvalid_0's l1: 6.33836\n",
      "[1152]\tvalid_0's l1: 6.33844\n",
      "[1156]\tvalid_0's l1: 6.33859\n",
      "[1160]\tvalid_0's l1: 6.33865\n",
      "[1164]\tvalid_0's l1: 6.33878\n",
      "Early stopping, best iteration is:\n",
      "[1066]\tvalid_0's l1: 6.338\n",
      "\n",
      "\n",
      "\n",
      "Train LGBM Regressor for cluster 4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35619\n",
      "[LightGBM] [Info] Number of data points in the train set: 56284, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 29.593750\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[4]\tvalid_0's l1: 8.1117\n",
      "[8]\tvalid_0's l1: 8.0829\n",
      "[12]\tvalid_0's l1: 8.05792\n",
      "[16]\tvalid_0's l1: 8.03201\n",
      "[20]\tvalid_0's l1: 8.00718\n",
      "[24]\tvalid_0's l1: 7.98466\n",
      "[28]\tvalid_0's l1: 7.96319\n",
      "[32]\tvalid_0's l1: 7.94166\n",
      "[36]\tvalid_0's l1: 7.92323\n",
      "[40]\tvalid_0's l1: 7.90461\n",
      "[44]\tvalid_0's l1: 7.88693\n",
      "[48]\tvalid_0's l1: 7.87138\n",
      "[52]\tvalid_0's l1: 7.8556\n",
      "[56]\tvalid_0's l1: 7.84036\n",
      "[60]\tvalid_0's l1: 7.82682\n",
      "[64]\tvalid_0's l1: 7.81297\n",
      "[68]\tvalid_0's l1: 7.80066\n",
      "[72]\tvalid_0's l1: 7.78844\n",
      "[76]\tvalid_0's l1: 7.77701\n",
      "[80]\tvalid_0's l1: 7.7654\n",
      "[84]\tvalid_0's l1: 7.75451\n",
      "[88]\tvalid_0's l1: 7.74375\n",
      "[92]\tvalid_0's l1: 7.73451\n",
      "[96]\tvalid_0's l1: 7.72518\n",
      "[100]\tvalid_0's l1: 7.71741\n",
      "[104]\tvalid_0's l1: 7.71099\n",
      "[108]\tvalid_0's l1: 7.70427\n",
      "[112]\tvalid_0's l1: 7.69749\n",
      "[116]\tvalid_0's l1: 7.69179\n",
      "[120]\tvalid_0's l1: 7.68668\n",
      "[124]\tvalid_0's l1: 7.68242\n",
      "[128]\tvalid_0's l1: 7.67681\n",
      "[132]\tvalid_0's l1: 7.67099\n",
      "[136]\tvalid_0's l1: 7.66607\n",
      "[140]\tvalid_0's l1: 7.66129\n",
      "[144]\tvalid_0's l1: 7.65681\n",
      "[148]\tvalid_0's l1: 7.65155\n",
      "[152]\tvalid_0's l1: 7.64766\n",
      "[156]\tvalid_0's l1: 7.64355\n",
      "[160]\tvalid_0's l1: 7.63855\n",
      "[164]\tvalid_0's l1: 7.63533\n",
      "[168]\tvalid_0's l1: 7.6307\n",
      "[172]\tvalid_0's l1: 7.62611\n",
      "[176]\tvalid_0's l1: 7.62298\n",
      "[180]\tvalid_0's l1: 7.61962\n",
      "[184]\tvalid_0's l1: 7.61579\n",
      "[188]\tvalid_0's l1: 7.61288\n",
      "[192]\tvalid_0's l1: 7.60918\n",
      "[196]\tvalid_0's l1: 7.60604\n",
      "[200]\tvalid_0's l1: 7.6025\n",
      "[204]\tvalid_0's l1: 7.59912\n",
      "[208]\tvalid_0's l1: 7.59678\n",
      "[212]\tvalid_0's l1: 7.59451\n",
      "[216]\tvalid_0's l1: 7.59281\n",
      "[220]\tvalid_0's l1: 7.59116\n",
      "[224]\tvalid_0's l1: 7.58894\n",
      "[228]\tvalid_0's l1: 7.58675\n",
      "[232]\tvalid_0's l1: 7.58471\n",
      "[236]\tvalid_0's l1: 7.58249\n",
      "[240]\tvalid_0's l1: 7.58024\n",
      "[244]\tvalid_0's l1: 7.57843\n",
      "[248]\tvalid_0's l1: 7.57696\n",
      "[252]\tvalid_0's l1: 7.57534\n",
      "[256]\tvalid_0's l1: 7.57385\n",
      "[260]\tvalid_0's l1: 7.57325\n",
      "[264]\tvalid_0's l1: 7.57192\n",
      "[268]\tvalid_0's l1: 7.57077\n",
      "[272]\tvalid_0's l1: 7.57022\n",
      "[276]\tvalid_0's l1: 7.56881\n",
      "[280]\tvalid_0's l1: 7.56856\n",
      "[284]\tvalid_0's l1: 7.56755\n",
      "[288]\tvalid_0's l1: 7.56673\n",
      "[292]\tvalid_0's l1: 7.56565\n",
      "[296]\tvalid_0's l1: 7.56469\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[300]\tvalid_0's l1: 7.56419\n",
      "[304]\tvalid_0's l1: 7.56342\n",
      "[308]\tvalid_0's l1: 7.56313\n",
      "[312]\tvalid_0's l1: 7.56282\n",
      "[316]\tvalid_0's l1: 7.56273\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[320]\tvalid_0's l1: 7.56199\n",
      "[324]\tvalid_0's l1: 7.56167\n",
      "[328]\tvalid_0's l1: 7.56147\n",
      "[332]\tvalid_0's l1: 7.56042\n",
      "[336]\tvalid_0's l1: 7.56057\n",
      "[340]\tvalid_0's l1: 7.5601\n",
      "[344]\tvalid_0's l1: 7.55909\n",
      "[348]\tvalid_0's l1: 7.55838\n",
      "[352]\tvalid_0's l1: 7.55822\n",
      "[356]\tvalid_0's l1: 7.5583\n",
      "[360]\tvalid_0's l1: 7.55703\n",
      "[364]\tvalid_0's l1: 7.55627\n",
      "[368]\tvalid_0's l1: 7.55598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[372]\tvalid_0's l1: 7.55594\n",
      "[376]\tvalid_0's l1: 7.55567\n",
      "[380]\tvalid_0's l1: 7.55497\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[384]\tvalid_0's l1: 7.554\n",
      "[388]\tvalid_0's l1: 7.55329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[392]\tvalid_0's l1: 7.55253\n",
      "[396]\tvalid_0's l1: 7.55159\n",
      "[400]\tvalid_0's l1: 7.55082\n",
      "[404]\tvalid_0's l1: 7.55041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[408]\tvalid_0's l1: 7.5501\n",
      "[412]\tvalid_0's l1: 7.54973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[416]\tvalid_0's l1: 7.5495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[420]\tvalid_0's l1: 7.54908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[424]\tvalid_0's l1: 7.54899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[428]\tvalid_0's l1: 7.54899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[432]\tvalid_0's l1: 7.54844\n",
      "[436]\tvalid_0's l1: 7.548\n",
      "[440]\tvalid_0's l1: 7.54769\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[444]\tvalid_0's l1: 7.54755\n",
      "[448]\tvalid_0's l1: 7.54713\n",
      "[452]\tvalid_0's l1: 7.54683\n",
      "[456]\tvalid_0's l1: 7.54678\n",
      "[460]\tvalid_0's l1: 7.54654\n",
      "[464]\tvalid_0's l1: 7.54638\n",
      "[468]\tvalid_0's l1: 7.54612\n",
      "[472]\tvalid_0's l1: 7.54559\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[476]\tvalid_0's l1: 7.54515\n",
      "[480]\tvalid_0's l1: 7.54491\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[484]\tvalid_0's l1: 7.54497\n",
      "[488]\tvalid_0's l1: 7.54474\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[492]\tvalid_0's l1: 7.54406\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[496]\tvalid_0's l1: 7.54405\n",
      "[500]\tvalid_0's l1: 7.54405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[504]\tvalid_0's l1: 7.54414\n",
      "[508]\tvalid_0's l1: 7.54425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[512]\tvalid_0's l1: 7.54432\n",
      "[516]\tvalid_0's l1: 7.54471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[520]\tvalid_0's l1: 7.54486\n",
      "[524]\tvalid_0's l1: 7.54485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[528]\tvalid_0's l1: 7.54475\n",
      "[532]\tvalid_0's l1: 7.54467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[536]\tvalid_0's l1: 7.54443\n",
      "[540]\tvalid_0's l1: 7.54419\n",
      "[544]\tvalid_0's l1: 7.54387\n",
      "[548]\tvalid_0's l1: 7.54353\n",
      "[552]\tvalid_0's l1: 7.54323\n",
      "[556]\tvalid_0's l1: 7.54282\n",
      "[560]\tvalid_0's l1: 7.54246\n",
      "[564]\tvalid_0's l1: 7.54211\n",
      "[568]\tvalid_0's l1: 7.54222\n",
      "[572]\tvalid_0's l1: 7.5421\n",
      "[576]\tvalid_0's l1: 7.54159\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[580]\tvalid_0's l1: 7.54128\n",
      "[584]\tvalid_0's l1: 7.54111\n",
      "[588]\tvalid_0's l1: 7.54059\n",
      "[592]\tvalid_0's l1: 7.54037\n",
      "[596]\tvalid_0's l1: 7.53955\n",
      "[600]\tvalid_0's l1: 7.53953\n",
      "[604]\tvalid_0's l1: 7.53941\n",
      "[608]\tvalid_0's l1: 7.53946\n",
      "[612]\tvalid_0's l1: 7.53943\n",
      "[616]\tvalid_0's l1: 7.53961\n",
      "[620]\tvalid_0's l1: 7.53973\n",
      "[624]\tvalid_0's l1: 7.53986\n",
      "[628]\tvalid_0's l1: 7.54013\n",
      "[632]\tvalid_0's l1: 7.53998\n",
      "[636]\tvalid_0's l1: 7.54007\n",
      "[640]\tvalid_0's l1: 7.54023\n",
      "[644]\tvalid_0's l1: 7.54023\n",
      "[648]\tvalid_0's l1: 7.54015\n",
      "[652]\tvalid_0's l1: 7.54013\n",
      "[656]\tvalid_0's l1: 7.54029\n",
      "[660]\tvalid_0's l1: 7.54018\n",
      "[664]\tvalid_0's l1: 7.53994\n",
      "[668]\tvalid_0's l1: 7.5398\n",
      "[672]\tvalid_0's l1: 7.53972\n",
      "[676]\tvalid_0's l1: 7.53998\n",
      "[680]\tvalid_0's l1: 7.53982\n",
      "[684]\tvalid_0's l1: 7.53982\n",
      "[688]\tvalid_0's l1: 7.53975\n",
      "[692]\tvalid_0's l1: 7.53977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[696]\tvalid_0's l1: 7.53978\n",
      "[700]\tvalid_0's l1: 7.54008\n",
      "[704]\tvalid_0's l1: 7.54024\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's l1: 7.53936\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.20\n",
    "stopping_rounds = 100\n",
    "log_evaluation_periods = 4\n",
    "\n",
    "lgb_params = {\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 164,\n",
    "    'objective': 'mae',\n",
    "    'n_estimators': 3000,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'learning_rate': 0.008,\n",
    "    'reg_alpha': 0.00001,\n",
    "    'reg_lambda': 0.00001,\n",
    "    'importance_type' : 'gain',\n",
    "    'subsample': 0.85,\n",
    "    'verbosity': 1,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for cluster_id in train['cluster'].unique():\n",
    "    print(f\"Train LGBM Regressor for cluster {cluster_id}\")\n",
    "    \n",
    "    cluster_data = train[train['cluster'] == cluster_id]\n",
    "    \n",
    "    columns_to_keep = [col for col in cluster_data.columns if 'cluster' not in col]\n",
    "    cluster_data = cluster_data[columns_to_keep]\n",
    "    \n",
    "    y = cluster_data['target']\n",
    "    X = cluster_data.drop(columns=['target', 'date_id'])\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    # Define a LightGBM model for the current fold\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    # Train the LightGBM model for the current fold\n",
    "    lgb_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=stopping_rounds),\n",
    "            lgb.callback.log_evaluation(period=log_evaluation_periods),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    models[cluster_id] = lgb_model\n",
    "        \n",
    "    # Free up memory by deleting fold specific variables\n",
    "    del X, y, cluster_data, X_train, y_train, X_valid, y_valid\n",
    "    \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103933b",
   "metadata": {
    "papermill": {
     "duration": 0.11329,
     "end_time": "2023-12-19T01:51:48.289160",
     "exception": false,
     "start_time": "2023-12-19T01:51:48.175870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d544cf95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T01:51:48.601213Z",
     "iopub.status.busy": "2023-12-19T01:51:48.600773Z",
     "iopub.status.idle": "2023-12-19T01:51:49.764783Z",
     "shell.execute_reply": "2023-12-19T01:51:49.763587Z"
    },
    "papermill": {
     "duration": 1.362976,
     "end_time": "2023-12-19T01:51:49.767418",
     "exception": false,
     "start_time": "2023-12-19T01:51:48.404442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "\n",
    "@nb.jit(nopython=False, parallel=True)\n",
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    return out\n",
    "    \n",
    "# Init a counter\n",
    "counter = 0\n",
    "\n",
    "# To clip predictions\n",
    "y_min, y_max = -64, 64\n",
    "\n",
    "# Init an empty dataframe\n",
    "cache = pd.DataFrame()\n",
    "\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:       \n",
    "    # Add data to the chache dataset\n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    if counter > 0:\n",
    "        cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "    \n",
    "    # First iteration \n",
    "    if test.currently_scored.iloc[0]==False:\n",
    "        sample_prediction['target'] = 0\n",
    "        env.predict(sample_prediction)\n",
    "        continue\n",
    "        \n",
    "    features = feat_eng(cache)[-len(test):]\n",
    "    features = features.drop(columns='date_id').reset_index(drop=True)\n",
    "    features['cluster'] = lgb_model_classifier.predict(features)\n",
    "    \n",
    "    predictions = np.zeros(len(test))\n",
    "    for i in range(n_models):\n",
    "        selected_indices = features[features['cluster']==i].index\n",
    "        if len(selected_indices) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            selected_features = features.iloc[selected_indices]\n",
    "            selected_features = selected_features.drop(columns=['cluster'])\n",
    "            if len(selected_indices) == 1:\n",
    "                selected_features = (selected_features.values).reshape(1, -1)\n",
    "        \n",
    "        model_predictions = models[i].predict(selected_features)\n",
    "        predictions[selected_indices] = model_predictions\n",
    "    \n",
    "    sample_prediction['target'] = zero_sum(predictions, test['bid_size'] + test['ask_size'])\n",
    "    \n",
    "    num_nan_values = sample_prediction['target'].isna().sum()\n",
    "    print(\"Numero di righe con valori NaN nella colonna 'target':\", num_nan_values)\n",
    "    \n",
    "    # Predict\n",
    "    env.predict(sample_prediction)\n",
    "        \n",
    "    # Update the counter\n",
    "    counter += 1\n",
    "    \n",
    "    # Run garbage collector\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10557.617338,
   "end_time": "2023-12-19T01:51:51.225772",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-18T22:55:53.608434",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
